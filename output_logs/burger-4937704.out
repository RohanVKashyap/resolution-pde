Job started on babel-8-9 at Mon May 26 03:45:43 EDT 2025
Job ID: 4937704
GPU information:
Mon May 26 03:45:43 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:56:00.0 Off |                    0 |
| N/A   29C    P8             31W /  315W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA L40S                    On  |   00000000:D6:00.0 Off |                    0 |
| N/A   23C    P8             32W /  315W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
CUDA devices:
CUDA_VISIBLE_DEVICES: 0,1
Using device: cuda
[2025-05-26 03:45:47,375][root][INFO] - model:
  _target_: models.s4_2d.S4NDModel
  d_input: 15
  d_output: 3
  d_model: 64
  n_layers: 4
  dropout: 0.2
  prenorm: false
dataset:
  reduced_batch: 1
  reduced_resolution: 2
  reduced_resolution_t: 1
  window_size: 15
  original_res: 512
  pde: navier_stokes_0
  data_path1: data/pdebench/ns_incom_inhom_2d_512-100.hdf5
training:
  batch_size: 4
  epochs: 100
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: navier_stokes_0_s4_2d/s4_2d
Model name: models.s4_2d.S4NDModel
PDE Dataset: navier_stokes_0
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 256, 256, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 256, 256, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> -0.002297842176631093 -0.0002518951368983835 0.8239261507987976 0.8426117300987244
Sample Input shape: torch.Size([4, 45, 256, 256])
Sample Output shape: torch.Size([4, 3, 256, 256])
[2025-05-26 03:46:19,293][models.s4][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-26 03:46:19,294][models.s4][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
[2025-05-26 03:46:19,297][models.s4nd][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-26 03:46:19,297][models.s4nd][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863591.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [512]

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.256892
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 128, 128, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 128, 128, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> 0.005564701743423939 -0.006745028775185347 1.4442678689956665 1.4442124366760254
Sample Input shape: torch.Size([4, 45, 128, 128])
Sample Output shape: torch.Size([4, 3, 128, 128])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863592.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [256, 512]

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.449299

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.329394
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 64, 64, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 64, 64, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> 0.0034056794829666615 0.00033602057374082506 0.9717463254928589 1.0143089294433594
Sample Input shape: torch.Size([4, 45, 64, 64])
Sample Output shape: torch.Size([4, 3, 64, 64])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863593.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [128, 256, 512]

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([4, 45, 128, 128]), y=torch.Size([4, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.219589

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.348244

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.501557
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 32, 32, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 32, 32, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> -0.0023420744109898806 0.0012180827325209975 0.9568561315536499 0.9787348508834839
Sample Input shape: torch.Size([4, 45, 32, 32])
Sample Output shape: torch.Size([4, 3, 32, 32])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863594.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [64, 128, 256, 512]

Evaluating at resolution: 64
Downsampled shapes: x=torch.Size([4, 45, 64, 64]), y=torch.Size([4, 3, 64, 64])
Resolution 64 - Relative L2 Loss: 0.209010

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([4, 45, 128, 128]), y=torch.Size([4, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.438260

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.633554

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.685087
Job completed at Mon May 26 03:49:05 EDT 2025
