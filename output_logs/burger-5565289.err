wandb: Currently logged in as: rohanvk (rohanvk-carnegie-mellon-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/rvk/wandb/run-20250922_183938-pggr6r7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-spaceship-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rohanvk-carnegie-mellon-university/unet1d
wandb: üöÄ View run at https://wandb.ai/rohanvk-carnegie-mellon-university/unet1d/runs/pggr6r7s
  0%|          | 0/100 [00:00<?, ?it/s]wandb: Currently logged in as: rohanvk (rohanvk-carnegie-mellon-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/rvk/wandb/run-20250922_183939-3dir0yfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-grass-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rohanvk-carnegie-mellon-university/unet1d
wandb: üöÄ View run at https://wandb.ai/rohanvk-carnegie-mellon-university/unet1d/runs/3dir0yfc
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [05:23<8:53:52, 323.56s/it]  1%|          | 1/100 [05:23<8:53:50, 323.54s/it]  2%|‚ñè         | 2/100 [10:46<8:48:04, 323.31s/it]  2%|‚ñè         | 2/100 [10:46<8:48:12, 323.39s/it]  3%|‚ñé         | 3/100 [16:07<8:40:41, 322.08s/it]  3%|‚ñé         | 3/100 [16:07<8:40:56, 322.23s/it]  4%|‚ñç         | 4/100 [21:29<8:35:09, 321.98s/it]  4%|‚ñç         | 4/100 [21:29<8:35:26, 322.15s/it]  5%|‚ñå         | 5/100 [26:50<8:29:40, 321.90s/it]  5%|‚ñå         | 5/100 [26:51<8:29:59, 322.10s/it]  6%|‚ñå         | 6/100 [32:13<8:24:28, 322.01s/it]  6%|‚ñå         | 6/100 [32:14<8:24:48, 322.22s/it]  7%|‚ñã         | 7/100 [37:37<8:20:31, 322.92s/it]  7%|‚ñã         | 7/100 [37:39<8:20:59, 323.22s/it]  8%|‚ñä         | 8/100 [43:05<8:17:23, 324.38s/it]  8%|‚ñä         | 8/100 [43:07<8:17:45, 324.63s/it]  9%|‚ñâ         | 9/100 [48:30<8:12:20, 324.62s/it]  9%|‚ñâ         | 9/100 [48:32<8:12:40, 324.85s/it] 10%|‚ñà         | 10/100 [54:00<8:09:29, 326.32s/it] 10%|‚ñà         | 10/100 [54:04<8:10:44, 327.16s/it] 11%|‚ñà         | 11/100 [59:34<8:07:28, 328.63s/it] 11%|‚ñà         | 11/100 [59:39<8:08:42, 329.46s/it] 12%|‚ñà‚ñè        | 12/100 [1:05:06<8:03:28, 329.64s/it] 12%|‚ñà‚ñè        | 12/100 [1:05:12<8:04:59, 330.67s/it] 13%|‚ñà‚ñé        | 13/100 [1:10:37<7:58:26, 329.96s/it] 13%|‚ñà‚ñé        | 13/100 [1:10:44<8:00:04, 331.08s/it] 14%|‚ñà‚ñç        | 14/100 [1:16:07<7:53:08, 330.10s/it] 14%|‚ñà‚ñç        | 14/100 [1:16:17<7:55:21, 331.64s/it] 15%|‚ñà‚ñå        | 15/100 [1:21:37<7:47:45, 330.18s/it] 15%|‚ñà‚ñå        | 15/100 [1:21:49<7:49:46, 331.60s/it] 16%|‚ñà‚ñå        | 16/100 [1:27:09<7:42:56, 330.67s/it] 16%|‚ñà‚ñå        | 16/100 [1:27:21<7:44:24, 331.72s/it] 17%|‚ñà‚ñã        | 17/100 [1:32:42<7:38:07, 331.17s/it] 17%|‚ñà‚ñã        | 17/100 [1:32:53<7:39:09, 331.92s/it] 18%|‚ñà‚ñä        | 18/100 [1:38:12<7:32:17, 330.95s/it] 18%|‚ñà‚ñä        | 18/100 [1:38:27<7:34:16, 332.40s/it] 19%|‚ñà‚ñâ        | 19/100 [1:43:42<7:26:19, 330.62s/it] 19%|‚ñà‚ñâ        | 19/100 [1:44:01<7:29:30, 332.97s/it] 20%|‚ñà‚ñà        | 20/100 [1:49:09<7:19:24, 329.55s/it] 20%|‚ñà‚ñà        | 20/100 [1:49:31<7:22:45, 332.07s/it] 21%|‚ñà‚ñà        | 21/100 [1:54:38<7:13:51, 329.51s/it] 21%|‚ñà‚ñà        | 21/100 [1:55:01<7:16:22, 331.42s/it] 22%|‚ñà‚ñà‚ñè       | 22/100 [2:00:07<7:08:01, 329.25s/it] 22%|‚ñà‚ñà‚ñè       | 22/100 [2:00:29<7:09:42, 330.55s/it] 23%|‚ñà‚ñà‚ñé       | 23/100 [2:05:33<7:01:10, 328.19s/it] 23%|‚ñà‚ñà‚ñé       | 23/100 [2:05:58<7:03:31, 330.01s/it] 24%|‚ñà‚ñà‚ñç       | 24/100 [2:11:01<6:55:45, 328.23s/it] 24%|‚ñà‚ñà‚ñç       | 24/100 [2:11:27<6:57:43, 329.79s/it] 25%|‚ñà‚ñà‚ñå       | 25/100 [2:16:28<6:49:55, 327.94s/it] 25%|‚ñà‚ñà‚ñå       | 25/100 [2:16:54<6:51:09, 328.92s/it] 26%|‚ñà‚ñà‚ñå       | 26/100 [2:21:56<6:44:29, 327.97s/it] 26%|‚ñà‚ñà‚ñå       | 26/100 [2:22:22<6:45:04, 328.43s/it] 27%|‚ñà‚ñà‚ñã       | 27/100 [2:27:25<6:39:13, 328.13s/it] 27%|‚ñà‚ñà‚ñã       | 27/100 [2:27:54<6:40:50, 329.46s/it] 28%|‚ñà‚ñà‚ñä       | 28/100 [2:32:53<6:33:54, 328.25s/it] 28%|‚ñà‚ñà‚ñä       | 28/100 [2:33:17<6:33:18, 327.76s/it] 29%|‚ñà‚ñà‚ñâ       | 29/100 [2:38:25<6:29:46, 329.39s/it] 29%|‚ñà‚ñà‚ñâ       | 29/100 [2:38:45<6:27:39, 327.60s/it] 30%|‚ñà‚ñà‚ñà       | 30/100 [2:43:55<6:24:12, 329.32s/it] 30%|‚ñà‚ñà‚ñà       | 30/100 [2:44:12<6:22:05, 327.51s/it] 31%|‚ñà‚ñà‚ñà       | 31/100 [2:49:22<6:18:07, 328.80s/it] 31%|‚ñà‚ñà‚ñà       | 31/100 [2:49:43<6:17:47, 328.51s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [2:54:50<6:12:10, 328.39s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [2:55:13<6:12:47, 328.93s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [3:00:20<6:07:15, 328.89s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [3:00:43<6:07:38, 329.24s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [3:05:47<6:01:14, 328.39s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [3:06:14<6:02:44, 329.76s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [3:11:13<5:55:01, 327.71s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [3:11:46<5:58:05, 330.55s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [3:16:40<5:49:16, 327.44s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [3:17:19<5:53:28, 331.39s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [3:22:08<5:43:52, 327.51s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [3:22:48<5:47:13, 330.69s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [3:27:31<5:37:13, 326.34s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [3:28:15<5:40:21, 329.37s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [3:33:03<5:33:24, 327.93s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [3:33:47<5:35:45, 330.26s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [3:38:32<5:28:21, 328.36s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [3:39:11<5:28:22, 328.38s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [3:44:00<5:22:42, 328.17s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [3:44:42<5:23:40, 329.16s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [3:49:26<5:16:43, 327.65s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [3:50:17<5:19:55, 330.97s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [3:54:53<5:11:05, 327.46s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [3:55:44<5:13:20, 329.82s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [4:00:21<5:05:43, 327.56s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [4:01:11<5:06:51, 328.77s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [4:05:48<4:59:56, 327.21s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [4:06:35<5:00:16, 327.57s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [4:11:15<4:54:39, 327.39s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [4:12:02<4:54:27, 327.18s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [4:16:47<4:50:21, 328.70s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [4:17:33<4:50:00, 328.31s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [4:22:16<4:44:49, 328.64s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [4:23:02<4:44:46, 328.59s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [4:27:46<4:39:51, 329.24s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [4:28:35<4:40:22, 329.85s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [4:33:16<4:34:25, 329.31s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [4:34:04<4:34:53, 329.87s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [4:38:45<4:29:02, 329.45s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [4:39:36<4:29:43, 330.28s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [4:44:15<4:23:40, 329.60s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [4:45:10<4:25:07, 331.40s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [4:49:45<4:18:03, 329.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [4:50:35<4:18:09, 329.56s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [4:55:13<4:12:26, 329.28s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [4:56:11<4:14:02, 331.37s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [5:00:40<4:06:19, 328.44s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [5:01:31<4:05:58, 327.97s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [5:06:11<4:01:23, 329.16s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [5:06:56<3:59:59, 327.26s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [5:11:37<3:55:19, 328.37s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [5:12:19<3:53:30, 325.82s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [5:17:03<3:49:14, 327.49s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [5:17:54<3:50:03, 328.64s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [5:22:23<3:42:17, 325.31s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [5:23:29<3:45:56, 330.65s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [5:27:48<3:36:52, 325.31s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [5:28:57<3:39:52, 329.80s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [5:33:16<3:31:57, 326.09s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [5:34:18<3:32:33, 327.00s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [5:38:51<3:28:08, 328.65s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [5:39:47<3:27:30, 327.64s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [5:44:18<3:22:20, 328.13s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [5:45:07<3:20:42, 325.48s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [5:49:46<3:16:55, 328.22s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [5:50:43<3:17:08, 328.57s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [5:55:10<3:10:38, 326.82s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [5:56:18<3:12:45, 330.43s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [6:00:35<3:04:51, 326.23s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [6:01:45<3:06:42, 329.48s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [6:06:00<2:59:16, 325.96s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [6:07:14<3:01:08, 329.34s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [6:11:26<2:53:54, 326.07s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [6:12:35<2:54:21, 326.91s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [6:17:00<2:49:44, 328.52s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [6:18:03<2:49:02, 327.17s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [6:22:21<2:43:03, 326.12s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [6:23:33<2:44:04, 328.16s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [6:27:53<2:38:29, 327.90s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [6:28:51<2:37:05, 325.03s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [6:33:26<2:33:44, 329.44s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [6:34:17<2:31:47, 325.27s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [6:38:53<2:27:52, 328.61s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [6:39:45<2:26:44, 326.08s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [6:44:15<2:21:37, 326.82s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [6:45:19<2:22:19, 328.46s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [6:49:34<2:15:06, 324.25s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [6:50:56<2:17:54, 330.98s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [6:54:56<2:09:28, 323.70s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [6:56:22<2:11:51, 329.66s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [7:00:24<2:04:34, 324.98s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [7:01:48<2:05:50, 328.29s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [7:05:52<1:59:27, 325.81s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [7:07:12<1:59:55, 327.07s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [7:11:19<1:54:12, 326.29s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [7:12:37<1:54:16, 326.50s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [7:16:46<1:48:47, 326.40s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [7:18:02<1:48:43, 326.18s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [7:22:15<1:43:36, 327.20s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [7:23:27<1:43:07, 325.65s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [7:27:43<1:38:13, 327.44s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [7:28:46<1:37:06, 323.69s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [7:33:17<1:33:19, 329.35s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [7:34:11<1:31:49, 324.06s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [7:38:44<1:27:37, 328.62s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [7:39:45<1:27:15, 327.24s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [7:44:13<1:22:14, 328.99s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [7:45:17<1:22:06, 328.45s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [7:49:33<1:16:05, 326.13s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [7:50:45<1:16:35, 328.25s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [7:55:26<1:12:24, 334.21s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [7:56:25<1:11:54, 331.87s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [8:00:46<1:05:58, 329.91s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [8:01:42<1:05:28, 327.34s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [8:06:01<59:39, 325.38s/it]   89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [8:06:56<59:17, 323.38s/it]   90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [8:11:11<53:28, 320.85s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [8:12:06<53:12, 319.29s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [8:16:20<47:35, 317.28s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [8:17:15<47:27, 316.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [8:21:30<42:00, 315.09s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [8:22:27<41:59, 314.88s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [8:26:42<36:39, 314.19s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [8:27:37<36:35, 313.67s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [8:31:58<31:29, 314.87s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [8:32:53<31:25, 314.20s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [8:37:12<26:11, 314.38s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [8:38:06<26:08, 313.79s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [8:42:24<20:55, 313.89s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [8:43:20<20:55, 313.99s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [8:47:36<15:40, 313.36s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [8:48:33<15:40, 313.60s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [8:52:50<10:26, 313.33s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [8:53:46<10:26, 313.41s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [8:58:02<05:13, 313.14s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [8:58:56<05:12, 312.54s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [9:03:14<00:00, 312.77s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [9:03:14<00:00, 325.95s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [9:03:47<00:00, 305.87s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [9:03:47<00:00, 326.27s/it]
Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 46, in forward
    enc1 = self.encoder1(x)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 46, in forward
    enc1 = self.encoder1(x)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<9 lines>...
        self.eps,
        ^^^^^^^^^
    )
    ^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/functional.py", line 2822, in batch_norm
    return torch.batch_norm(
           ~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<7 lines>...
        torch.backends.cudnn.enabled,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 51, in forward
    bottleneck = self.bottleneck(self.pool4(enc4))
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 46, in forward
    enc1 = self.encoder1(x)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 48, in forward
    enc3 = self.encoder3(self.pool2(enc2))
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<9 lines>...
        self.eps,
        ^^^^^^^^^
    )
    ^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/functional.py", line 2822, in batch_norm
    return torch.batch_norm(
           ~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<7 lines>...
        torch.backends.cudnn.enabled,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 47, in forward
    enc2 = self.encoder2(self.pool1(enc1))
                         ~~~~~~~~~~^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 134, in forward
    return F.max_pool1d(
           ~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<5 lines>...
        return_indices=self.return_indices,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/_jit_internal.py", line 624, in fn
    return if_false(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/functional.py", line 740, in _max_pool1d
    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 51, in forward
    bottleneck = self.bottleneck(self.pool4(enc4))
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 51, in forward
    bottleneck = self.bottleneck(self.pool4(enc4))
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/rvk/utils/naive_utils.py", line 182, in evaluate_1d_all_resolution
    batch_pred_normalized = model(batch_x_normalized)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rvk/models/unet.py", line 51, in forward
    bottleneck = self.bottleneck(self.pool4(enc4))
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user_data/rvk/pde/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
           ~~~~~~~~^
        input, weight, bias, self.stride, self.padding, self.dilation, self.groups
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Error executing job with overrides: ['model=unet/unet_1d', 'dataset=burger/burger_naive_true_mres5']
Traceback (most recent call last):
  File "/home/rvk/main_1d.py", line 272, in main
    rollout_steps=args.dataset.rollout_steps,   # IMPORTANT
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'rollout_steps' is not in struct
    full_key: dataset.rollout_steps
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Error executing job with overrides: ['model=unet/unet_1d', 'dataset=burger/burger_naive_true_mres4']
Traceback (most recent call last):
  File "/home/rvk/main_1d.py", line 272, in main
    rollout_steps=args.dataset.rollout_steps,   # IMPORTANT
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'rollout_steps' is not in struct
    full_key: dataset.rollout_steps
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
