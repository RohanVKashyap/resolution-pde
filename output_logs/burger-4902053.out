Job started on babel-5-31 at Fri May 16 00:08:11 EDT 2025
Job ID: 4902053
GPU information:
Fri May 16 00:08:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:61:00.0 Off |                    0 |
| N/A   43C    P0             59W /  204W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
CUDA devices:
CUDA_VISIBLE_DEVICES: 0
Using device: cuda
[2025-05-16 00:08:17,065][root][INFO] - model:
  _target_: models.s4_2d.S4NDModel
  d_input: 15
  d_output: 3
  d_model: 64
  n_layers: 4
  dropout: 0.2
  prenorm: false
dataset:
  reduced_batch: 1
  reduced_resolution: 1
  reduced_resolution_t: 4
  window_size: 15
  original_res: 512
  pde: navier_stokes_0
  data_path1: data/pdebench/ns_incom_inhom_2d_512-0.hdf5
training:
  batch_size: 16
  epochs: 100
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: navier_stokes_0_s4_2d/s4_2d
Model name: models.s4_2d.S4NDModel
PDE Dataset: navier_stokes_0
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
<class 'torch.Tensor'> -0.014186752960085869 -0.014105045236647129 1.0721869468688965 1.0754344463348389
Sample Input shape: torch.Size([16, 45, 512, 512])
Sample Output shape: torch.Size([16, 3, 512, 512])
[2025-05-16 00:09:24,516][models.s4][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-16 00:09:24,517][models.s4][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
[2025-05-16 00:09:24,522][models.s4nd][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-16 00:09:24,522][models.s4nd][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863590.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
Original test data shape: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Testing resolutions: []
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 256, 256, 3)
x shape: torch.Size([940, 45, 256, 256])
y shape: torch.Size([940, 3, 256, 256])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
<class 'torch.Tensor'> 0.01198411826044321 0.013653253205120564 1.156786561012268 1.0845049619674683
Sample Input shape: torch.Size([16, 45, 256, 256])
Sample Output shape: torch.Size([16, 3, 256, 256])
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863591.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
Original test data shape: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Testing resolutions: [512]

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Error evaluating resolution 512: CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.57 GiB is free. Including non-PyTorch memory, this process has 74.68 GiB memory in use. Of the allocated memory 71.48 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 128, 128, 3)
x shape: torch.Size([940, 45, 128, 128])
y shape: torch.Size([940, 3, 128, 128])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
<class 'torch.Tensor'> 0.017724154517054558 0.019400259479880333 0.8431936502456665 0.8697519898414612
Sample Input shape: torch.Size([16, 45, 128, 128])
Sample Output shape: torch.Size([16, 3, 128, 128])
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863592.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
Original test data shape: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Testing resolutions: [256, 512]

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([94, 45, 256, 256]), y=torch.Size([94, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.568544

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Error evaluating resolution 512: CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.25 GiB of which 8.57 GiB is free. Including non-PyTorch memory, this process has 70.68 GiB memory in use. Of the allocated memory 55.21 GiB is allocated by PyTorch, and 14.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 64, 64, 3)
x shape: torch.Size([940, 45, 64, 64])
y shape: torch.Size([940, 3, 64, 64])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
<class 'torch.Tensor'> 0.0013033866416662931 0.0025520718190819025 0.8416366577148438 0.8687459826469421
Sample Input shape: torch.Size([16, 45, 64, 64])
Sample Output shape: torch.Size([16, 3, 64, 64])
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863593.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
Original test data shape: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Testing resolutions: [128, 256, 512]

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([94, 45, 128, 128]), y=torch.Size([94, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.318275

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([94, 45, 256, 256]), y=torch.Size([94, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.460960

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Error evaluating resolution 512: CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.25 GiB of which 8.57 GiB is free. Including non-PyTorch memory, this process has 70.68 GiB memory in use. Of the allocated memory 55.21 GiB is allocated by PyTorch, and 14.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 32, 32, 3)
x shape: torch.Size([940, 45, 32, 32])
y shape: torch.Size([940, 3, 32, 32])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
<class 'torch.Tensor'> -0.005335240159183741 -0.003979573957622051 0.9950887560844421 1.0029349327087402
Sample Input shape: torch.Size([16, 45, 32, 32])
Sample Output shape: torch.Size([16, 3, 32, 32])
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4863594.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 250)
Combined data shape: (4, 250, 512, 512, 3)
x shape: torch.Size([940, 45, 512, 512])
y shape: torch.Size([940, 3, 512, 512])
---------Using data normalizer---------------
Train dataset size: 752
Validation dataset size: 94
Test dataset size: 94
Original test data shape: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Testing resolutions: [64, 128, 256, 512]

Evaluating at resolution: 64
Downsampled shapes: x=torch.Size([94, 45, 64, 64]), y=torch.Size([94, 3, 64, 64])
Resolution 64 - Relative L2 Loss: 0.281983

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([94, 45, 128, 128]), y=torch.Size([94, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.648409

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([94, 45, 256, 256]), y=torch.Size([94, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.871317

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([94, 45, 512, 512]), y=torch.Size([94, 3, 512, 512])
Error evaluating resolution 512: CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.25 GiB of which 8.56 GiB is free. Including non-PyTorch memory, this process has 70.68 GiB memory in use. Of the allocated memory 55.21 GiB is allocated by PyTorch, and 14.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Job completed at Fri May 16 00:14:04 EDT 2025
