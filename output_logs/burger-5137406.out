Job started on babel-10-17 at Fri Jun 20 14:54:35 EDT 2025
Job ID: 5137406
GPU information:
Fri Jun 20 14:54:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:21:00.0 Off |                  Off |
| 30%   29C    P8             23W /  300W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:E1:00.0 Off |                  Off |
| 30%   25C    P8             21W /  300W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
CUDA devices:
CUDA_VISIBLE_DEVICES: 0,1
Using device: cuda
[2025-06-20 14:54:38,931][root][INFO] - model:
  _target_: models.CNO2d.CNO2d
  in_dim: 3
  out_dim: 3
  N_layers: 1
  N_res: 4
  N_res_neck: 4
  channel_multiplier: 16
  use_bn: false
dataset:
  reduced_batch: 1
  reduced_resolution: 1
  reduced_resolution_t: 1
  window_size: 15
  original_res: 512
  train_resolution: 512
  multi_res:
  - 1
  - 4
  s: 512
  train_mres: false
  pde: navier_stokes_0
  data_path1: data/pdebench/ns_incom_inhom_2d_512-0.hdf5
training:
  batch_size: 2
  epochs: 1
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: navier_stokes_0_cno_2d/cno_2d
Model name: models.CNO2d.CNO2d
PDE Dataset: navier_stokes_0
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Combined data shape: (4, 1000, 512, 512, 3)
Current Spatial Size: 512
x shape: torch.Size([3992, 3, 512, 512])
y shape: torch.Size([3992, 3, 512, 512])
---------Computing min-max normalization statistics---------------
Input data range: [-2.759037, 2.506686]
Output data range: [-2.752234, 2.492671]
Train dataset size: 3193
Validation dataset size: 399
Test dataset size: 400
<class 'torch.Tensor'> 0.5239453911781311 0.5247277617454529 0.09750964492559433 0.09786403924226761
Sample Input shape: torch.Size([2, 3, 512, 512])
Sample Output shape: torch.Size([2, 3, 512, 512])
Using provided normalization statistics from training resolution 512:
  Input range: [-2.759037, 2.506686]
  Output range: [-2.752234, 2.492671]
Loading original resolution (512) test data...
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-0.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Combined data shape: (4, 1000, 512, 512, 3)
Current Spatial Size: 512
x shape: torch.Size([3992, 3, 512, 512])
y shape: torch.Size([3992, 3, 512, 512])
Train dataset size: 3193
Validation dataset size: 399
Test dataset size: 400
Original test data shape: x=torch.Size([400, 3, 512, 512]), y=torch.Size([400, 3, 512, 512])
Testing resolutions: [32, 64, 128, 256, 512]

Evaluating at resolution: 32
Resizing data...
Resized shapes: x=torch.Size([400, 3, 32, 32]), y=torch.Size([400, 3, 32, 32])
Error evaluating resolution 32: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 32.49 GiB memory in use. Of the allocated memory 21.50 GiB is allocated by PyTorch, and 10.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Evaluating at resolution: 64
Resizing data...
Resized shapes: x=torch.Size([400, 3, 64, 64]), y=torch.Size([400, 3, 64, 64])
Error evaluating resolution 64: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 32.49 GiB memory in use. Of the allocated memory 16.07 GiB is allocated by PyTorch, and 15.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Evaluating at resolution: 128
Resizing data...
Resized shapes: x=torch.Size([400, 3, 128, 128]), y=torch.Size([400, 3, 128, 128])
Error evaluating resolution 128: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 32.49 GiB memory in use. Of the allocated memory 16.27 GiB is allocated by PyTorch, and 15.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Evaluating at resolution: 256
Resizing data...
Resized shapes: x=torch.Size([400, 3, 256, 256]), y=torch.Size([400, 3, 256, 256])
Error evaluating resolution 256: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 32.49 GiB memory in use. Of the allocated memory 17.09 GiB is allocated by PyTorch, and 14.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Evaluating at resolution: 512
Resizing data...
Resized shapes: x=torch.Size([400, 3, 512, 512]), y=torch.Size([400, 3, 512, 512])
Error evaluating resolution 512: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 32.49 GiB memory in use. Of the allocated memory 20.38 GiB is allocated by PyTorch, and 11.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

==================================================
EVALUATION SUMMARY
==================================================
Job completed at Fri Jun 20 14:55:56 EDT 2025
