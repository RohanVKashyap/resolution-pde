Job started on babel-12-17 at Tue Apr 22 11:08:11 EDT 2025
Job ID: 4624540
GPU information:
Tue Apr 22 11:08:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:01:00.0 Off |                  Off |
| 30%   37C    P8             29W /  204W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:23:00.0 Off |                  Off |
| 30%   36C    P8             21W /  204W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
CUDA devices:
CUDA_VISIBLE_DEVICES: 0,1
Using device: cuda
[2025-04-22 11:08:16,095][root][INFO] - model:
  _target_: models.s4_1d.S4Model
  d_input: 15
  d_output: 1
  d_model: 64
  n_layers: 4
  dropout: 0.2
  prenorm: false
dataset:
  reduced_batch: 4
  reduced_resolution: 16
  reduced_resolution_t: 1
  window_size: 15
  original_res: 1024
  pde: burger_0.001
  data_path1: data/pdebench/1D_Burgers_Sols_Nu0.001.hdf5
training:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: burger_0.001_s4_1d/s4_1d
Model name: models.s4_1d.S4Model
PDE Dataset: burger_0.001
Loading from file: /home/rvk/data/pdebench/1D_Burgers_Sols_Nu0.001.hdf5
(10000, 201, 1024)
Total data shape: (2500, 201, 64)
x shape: (465000, 15, 64)
y shape: (465000, 1, 64)
grid shape: torch.Size([64, 1])
---------Using data normalizer---------------
Train dataset size: 372000
Validation dataset size: 46500
Test dataset size: 46500
<class 'torch.Tensor'> -0.22930356860160828 -0.232537642121315 1.1322541236877441 1.1365121603012085
Sample Input shape: torch.Size([64, 15, 64])
Sample Output shape: torch.Size([64, 1, 64])
[2025-04-22 11:08:47,809][models.s4][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-04-22 11:08:47,810][models.s4][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
[2025-04-22 11:08:48,803][models.s4][INFO] - Constructing S4 (H, N, L) = (64, 32, None)
[2025-04-22 11:08:49,020][models.s4][INFO] - Constructing S4 (H, N, L) = (64, 32, None)
[2025-04-22 11:08:49,211][models.s4][INFO] - Constructing S4 (H, N, L) = (64, 32, None)
[2025-04-22 11:08:49,449][models.s4][INFO] - Constructing S4 (H, N, L) = (64, 32, None)
S4Model(
  (encoder): Linear(in_features=16, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4Block(
      (layer): FFTConv(
        (activation): GELU(approximate='none')
        (kernel): SSMKernelDPLR()
        (drop): Dropout(p=0.2, inplace=False)
        (drop_kernel): Identity()
      )
      (mult_activation): Identity()
      (drop): Dropout(p=0.2, inplace=False)
      (output_linear): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): GLU(dim=-1)
      )
      (residual_layer): ZeroLayer()
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=1, bias=True)
)
[2025-04-22 11:09:02,254][models.s4][INFO] - S4: Initializing kernel to length 64
[2025-04-22 11:09:02,637][models.s4][INFO] - S4: Initializing kernel to length 64
[2025-04-22 11:09:02,641][models.s4][INFO] - S4: Initializing kernel to length 64
[2025-04-22 11:09:02,645][models.s4][INFO] - S4: Initializing kernel to length 64
Epoch 0, Train Loss: 0.03569937, Val Loss: 0.01287507
Epoch 10, Train Loss: 0.01013633, Val Loss: 0.00654002
Epoch 20, Train Loss: 0.00890018, Val Loss: 0.00602907
Epoch 30, Train Loss: 0.00826096, Val Loss: 0.00677084
Epoch 40, Train Loss: 0.00777710, Val Loss: 0.00586280
Epoch 50, Train Loss: 0.00732746, Val Loss: 0.00481561
Epoch 60, Train Loss: 0.00697559, Val Loss: 0.00455551
Epoch 70, Train Loss: 0.00670944, Val Loss: 0.00480976
Epoch 80, Train Loss: 0.00649315, Val Loss: 0.00470144
Epoch 90, Train Loss: 0.00636194, Val Loss: 0.00454125
Test L2 Loss: 0.004575
-----Visualizing Saved------
Figure saved to output_logs/predictions/burger_0.001_fno_4624540_predictions.png
Model saved to checkpoints/s4model/burger_0.001_4624540.pt
Original test data shape: x=torch.Size([46500, 15, 64]), y=torch.Size([46500, 1, 64])

Evaluating at resolution factor: 1
Resolution factor 1 - Relative L2 Loss: 0.004575

Evaluating at resolution factor: 2
Downsampled shapes: x=torch.Size([46500, 15, 32]), y=torch.Size([46500, 1, 32])
Resolution factor 2 - Relative L2 Loss: 0.031879

Evaluating at resolution factor: 4
Downsampled shapes: x=torch.Size([46500, 15, 16]), y=torch.Size([46500, 1, 16])
Resolution factor 4 - Relative L2 Loss: 0.049392

Evaluating at resolution factor: 8
Downsampled shapes: x=torch.Size([46500, 15, 8]), y=torch.Size([46500, 1, 8])
Resolution factor 8 - Relative L2 Loss: 0.052596

Evaluating at resolution factor: 16
Downsampled shapes: x=torch.Size([46500, 15, 4]), y=torch.Size([46500, 1, 4])
Resolution factor 16 - Relative L2 Loss: 0.047421

Evaluating at resolution factor: 32
Downsampled shapes: x=torch.Size([46500, 15, 2]), y=torch.Size([46500, 1, 2])
Resolution factor 32 - Relative L2 Loss: 0.044457
Loading from file: /home/rvk/data/pdebench/1D_Burgers_Sols_Nu0.001.hdf5
(10000, 201, 1024)
Total data shape: (2500, 201, 1024)
x shape: (465000, 15, 1024)
y shape: (465000, 1, 1024)
grid shape: torch.Size([1024, 1])
---------Using data normalizer---------------
Train dataset size: 372000
Validation dataset size: 46500
Test dataset size: 46500
Original test data shape: x=torch.Size([46500, 15, 1024]), y=torch.Size([46500, 1, 1024])
Testing resolutions: [128, 256, 512, 1024]

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([46500, 15, 128]), y=torch.Size([46500, 1, 128])
[2025-04-22 13:37:30,928][models.s4][INFO] - S4: Doubling length from L = 64 to 128
[2025-04-22 13:37:30,936][models.s4][INFO] - S4: Doubling length from L = 64 to 128
[2025-04-22 13:37:30,939][models.s4][INFO] - S4: Doubling length from L = 64 to 128
[2025-04-22 13:37:30,942][models.s4][INFO] - S4: Doubling length from L = 64 to 128
Resolution 128 - Relative L2 Loss: 0.357746

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([46500, 15, 256]), y=torch.Size([46500, 1, 256])
[2025-04-22 13:37:36,207][models.s4][INFO] - S4: Doubling length from L = 128 to 256
[2025-04-22 13:37:36,215][models.s4][INFO] - S4: Doubling length from L = 128 to 256
[2025-04-22 13:37:36,218][models.s4][INFO] - S4: Doubling length from L = 128 to 256
[2025-04-22 13:37:36,221][models.s4][INFO] - S4: Doubling length from L = 128 to 256
Resolution 256 - Relative L2 Loss: 0.291376

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([46500, 15, 512]), y=torch.Size([46500, 1, 512])
[2025-04-22 13:37:42,448][models.s4][INFO] - S4: Doubling length from L = 256 to 512
[2025-04-22 13:37:42,465][models.s4][INFO] - S4: Doubling length from L = 256 to 512
[2025-04-22 13:37:42,468][models.s4][INFO] - S4: Doubling length from L = 256 to 512
[2025-04-22 13:37:42,471][models.s4][INFO] - S4: Doubling length from L = 256 to 512
Resolution 512 - Relative L2 Loss: 0.176439

Evaluating at resolution: 1024
Downsampled shapes: x=torch.Size([46500, 15, 1024]), y=torch.Size([46500, 1, 1024])
[2025-04-22 13:37:50,644][models.s4][INFO] - S4: Doubling length from L = 512 to 1024
[2025-04-22 13:37:50,655][models.s4][INFO] - S4: Doubling length from L = 512 to 1024
[2025-04-22 13:37:50,658][models.s4][INFO] - S4: Doubling length from L = 512 to 1024
[2025-04-22 13:37:50,662][models.s4][INFO] - S4: Doubling length from L = 512 to 1024
Resolution 1024 - Relative L2 Loss: 0.172490

Summary of Super-Resolution Evaluation:
Resolution factor 1: Relative L2 Loss = 0.004575
Resolution factor 2: Relative L2 Loss = 0.031879
Resolution factor 4: Relative L2 Loss = 0.049392
Resolution factor 8: Relative L2 Loss = 0.052596
Resolution factor 16: Relative L2 Loss = 0.047421
Resolution factor 32: Relative L2 Loss = 0.044457

Summary of Higher-Resolution Evaluation:
Resolution 128: Relative L2 Loss = 0.357746
Resolution 256: Relative L2 Loss = 0.291376
Resolution 512: Relative L2 Loss = 0.176439
Resolution 1024: Relative L2 Loss = 0.172490
Job completed at Tue Apr 22 13:38:07 EDT 2025
