/home/rvk/miniconda3/envs/pos/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of ScOT were not initialized from the model checkpoint at camlab-ethz/Poseidon-T and are newly initialized: ['decoder.layers.0.blocks.7.layernorm_after.weight.weight', 'decoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.2.blocks.4.layernorm_after.weight.weight', 'encoder.layers.3.blocks.6.intermediate.dense.bias', 'decoder.layers.0.blocks.5.attention.self.logit_scale', 'encoder.layers.3.blocks.4.layernorm_before.bias.bias', 'encoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.3.blocks.6.attention.self.value.weight', 'encoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.7.attention.output.dense.weight', 'encoder.layers.0.blocks.4.layernorm_after.weight.bias', 'decoder.layers.3.blocks.6.layernorm_before.weight.bias', 'encoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.3.blocks.6.layernorm_after.bias.bias', 'encoder.layers.3.blocks.4.attention.output.dense.weight', 'decoder.layers.3.blocks.5.layernorm_after.weight.bias', 'encoder.layers.1.blocks.6.attention.self.key.weight', 'encoder.layers.1.blocks.6.layernorm_after.bias.weight', 'decoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.2.blocks.5.layernorm_before.weight.bias', 'decoder.layers.3.blocks.7.layernorm_after.weight.weight', 'encoder.layers.2.blocks.5.attention.self.logit_scale', 'decoder.layers.1.blocks.6.output.dense.weight', 'encoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.4.layernorm_before.weight.bias', 'encoder.layers.2.blocks.6.attention.output.dense.bias', 'encoder.layers.3.blocks.5.layernorm_after.bias.bias', 'decoder.layers.0.blocks.6.layernorm_before.bias.bias', 'encoder.layers.0.blocks.5.output.dense.bias', 'decoder.layers.1.blocks.4.layernorm_before.weight.bias', 'encoder.layers.2.blocks.7.output.dense.weight', 'decoder.layers.1.blocks.5.layernorm_after.bias.bias', 'encoder.layers.1.blocks.5.attention.self.key.weight', 'decoder.layers.2.blocks.5.attention.self.logit_scale', 'decoder.layers.1.blocks.6.attention.output.dense.weight', 'encoder.layers.3.blocks.7.layernorm_before.weight.weight', 'encoder.layers.0.blocks.5.layernorm_before.weight.bias', 'encoder.layers.2.blocks.7.attention.self.logit_scale', 'decoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.0.blocks.5.attention.self.value.bias', 'decoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.5.layernorm_after.bias.bias', 'encoder.layers.2.blocks.6.attention.self.key.weight', 'encoder.layers.0.blocks.5.attention.self.logit_scale', 'decoder.layers.2.blocks.4.layernorm_after.bias.weight', 'decoder.layers.1.blocks.6.attention.self.key.weight', 'encoder.layers.0.blocks.6.intermediate.dense.bias', 'encoder.layers.2.blocks.6.layernorm_after.bias.weight', 'decoder.layers.2.blocks.7.layernorm_after.weight.weight', 'encoder.layers.2.blocks.4.layernorm_before.bias.bias', 'decoder.layers.1.blocks.4.output.dense.bias', 'decoder.layers.0.blocks.4.output.dense.bias', 'decoder.layers.0.blocks.6.attention.self.query.bias', 'decoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.7.attention.self.query.weight', 'decoder.layers.0.blocks.5.attention.output.dense.weight', 'decoder.layers.0.blocks.6.layernorm_before.weight.weight', 'encoder.layers.3.blocks.6.layernorm_after.weight.bias', 'decoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.6.layernorm_after.weight.weight', 'decoder.layers.2.blocks.4.attention.output.dense.bias', 'decoder.layers.3.blocks.6.layernorm_after.weight.weight', 'decoder.layers.2.blocks.6.attention.output.dense.bias', 'encoder.layers.2.blocks.6.attention.output.dense.weight', 'decoder.layers.3.blocks.7.intermediate.dense.weight', 'decoder.layers.3.blocks.4.intermediate.dense.weight', 'decoder.layers.1.blocks.4.attention.self.query.weight', 'encoder.layers.3.blocks.7.attention.self.value.bias', 'encoder.layers.0.blocks.4.attention.self.value.bias', 'encoder.layers.0.blocks.5.intermediate.dense.bias', 'encoder.layers.2.blocks.7.output.dense.bias', 'decoder.layers.0.blocks.5.layernorm_before.bias.weight', 'decoder.layers.0.blocks.5.intermediate.dense.weight', 'encoder.layers.0.blocks.6.layernorm_before.weight.weight', 'encoder.layers.1.blocks.5.attention.self.value.bias', 'decoder.layers.0.blocks.5.attention.self.value.bias', 'encoder.layers.2.blocks.4.attention.output.dense.weight', 'encoder.layers.2.blocks.7.attention.output.dense.weight', 'decoder.layers.0.blocks.5.output.dense.weight', 'decoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.1.blocks.7.attention.self.value.weight', 'encoder.layers.1.blocks.7.attention.output.dense.bias', 'encoder.layers.2.blocks.7.attention.output.dense.bias', 'decoder.layers.3.blocks.7.output.dense.weight', 'decoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.2.blocks.5.attention.self.value.weight', 'encoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.7.layernorm_before.bias.weight', 'encoder.layers.3.blocks.6.layernorm_after.weight.weight', 'encoder.layers.1.blocks.4.layernorm_before.weight.weight', 'decoder.layers.2.blocks.4.attention.self.value.weight', 'decoder.layers.1.blocks.7.intermediate.dense.weight', 'encoder.layers.0.blocks.4.attention.self.query.weight', 'encoder.layers.3.blocks.7.attention.output.dense.weight', 'decoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.3.blocks.5.attention.output.dense.bias', 'encoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.2.blocks.4.layernorm_before.weight.bias', 'encoder.layers.2.blocks.5.attention.self.query.weight', 'encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.2.blocks.5.attention.output.dense.bias', 'encoder.layers.0.blocks.7.layernorm_before.bias.weight', 'encoder.layers.2.blocks.6.layernorm_after.weight.bias', 'encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.1.blocks.5.attention.self.query.weight', 'decoder.layers.2.blocks.6.attention.self.key.weight', 'decoder.layers.0.blocks.7.attention.self.value.bias', 'encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.0.blocks.6.layernorm_before.weight.bias', 'encoder.layers.1.blocks.6.intermediate.dense.weight', 'decoder.layers.2.blocks.5.layernorm_before.weight.weight', 'encoder.layers.0.blocks.6.layernorm_before.bias.weight', 'encoder.layers.3.blocks.6.layernorm_before.weight.weight', 'encoder.layers.3.blocks.4.intermediate.dense.bias', 'encoder.layers.3.blocks.5.attention.self.value.weight', 'decoder.layers.2.blocks.5.layernorm_before.weight.bias', 'encoder.layers.2.blocks.4.layernorm_after.weight.bias', 'decoder.layers.3.blocks.7.layernorm_after.weight.bias', 'encoder.layers.3.blocks.4.attention.self.value.bias', 'decoder.layers.0.blocks.4.intermediate.dense.bias', 'encoder.layers.3.blocks.4.output.dense.bias', 'decoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.0.blocks.6.attention.output.dense.weight', 'decoder.layers.2.blocks.6.attention.self.logit_scale', 'decoder.layers.2.blocks.4.layernorm_after.weight.weight', 'encoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.4.layernorm_before.weight.weight', 'encoder.layers.1.blocks.5.intermediate.dense.bias', 'encoder.layers.1.blocks.7.attention.self.query.bias', 'encoder.layers.1.blocks.5.layernorm_before.weight.bias', 'decoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.1.blocks.6.layernorm_before.bias.weight', 'decoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.6.output.dense.bias', 'encoder.layers.1.blocks.6.attention.self.value.weight', 'decoder.layers.3.blocks.7.attention.self.logit_scale', 'encoder.layers.0.blocks.6.attention.self.query.weight', 'decoder.layers.3.blocks.7.attention.self.value.weight', 'decoder.layers.0.blocks.4.layernorm_after.weight.weight', 'encoder.layers.3.blocks.7.layernorm_before.bias.bias', 'decoder.layers.1.blocks.6.intermediate.dense.weight', 'decoder.layers.1.blocks.7.layernorm_after.weight.weight', 'decoder.layers.3.blocks.5.attention.self.query.weight', 'decoder.layers.0.blocks.4.attention.self.query.weight', 'decoder.layers.1.blocks.6.layernorm_after.weight.bias', 'encoder.layers.0.blocks.7.attention.self.query.bias', 'encoder.layers.1.blocks.4.attention.self.logit_scale', 'decoder.layers.2.blocks.7.attention.self.value.bias', 'decoder.layers.0.blocks.6.output.dense.weight', 'encoder.layers.3.blocks.7.layernorm_before.bias.weight', 'encoder.layers.2.blocks.5.attention.self.value.weight', 'decoder.layers.3.blocks.5.attention.self.logit_scale', 'encoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.0.blocks.4.layernorm_before.bias.weight', 'encoder.layers.1.blocks.5.attention.self.logit_scale', 'decoder.layers.3.blocks.6.intermediate.dense.bias', 'decoder.layers.1.blocks.7.attention.self.key.weight', 'encoder.layers.2.blocks.6.layernorm_after.bias.bias', 'encoder.layers.2.blocks.4.attention.self.key.weight', 'decoder.layers.2.blocks.4.layernorm_before.weight.weight', 'decoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.2.blocks.4.intermediate.dense.weight', 'encoder.layers.3.blocks.7.attention.self.query.weight', 'encoder.layers.2.blocks.4.output.dense.weight', 'encoder.layers.1.blocks.4.layernorm_after.weight.bias', 'encoder.layers.2.blocks.4.attention.self.query.weight', 'encoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.2.blocks.5.attention.self.key.weight', 'encoder.layers.2.blocks.7.intermediate.dense.weight', 'decoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.2.blocks.5.output.dense.weight', 'encoder.layers.1.blocks.6.layernorm_before.weight.weight', 'encoder.layers.0.blocks.7.attention.output.dense.weight', 'encoder.layers.1.blocks.5.attention.output.dense.bias', 'encoder.layers.1.blocks.5.layernorm_before.bias.weight', 'decoder.layers.3.blocks.4.layernorm_after.weight.bias', 'decoder.layers.1.blocks.7.attention.self.query.bias', 'decoder.layers.3.blocks.6.output.dense.bias', 'decoder.layers.3.blocks.7.attention.output.dense.weight', 'decoder.layers.0.blocks.5.attention.output.dense.bias', 'encoder.layers.2.blocks.7.attention.self.query.bias', 'encoder.layers.3.blocks.6.layernorm_before.bias.weight', 'encoder.layers.2.blocks.7.layernorm_before.bias.weight', 'encoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.1.blocks.4.layernorm_after.weight.weight', 'decoder.layers.3.blocks.4.layernorm_after.weight.weight', 'encoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.2.blocks.4.layernorm_before.weight.bias', 'decoder.layers.2.blocks.4.layernorm_before.bias.weight', 'encoder.layers.3.blocks.5.attention.self.value.bias', 'decoder.layers.2.blocks.4.attention.self.value.bias', 'encoder.layers.3.blocks.6.attention.output.dense.bias', 'decoder.layers.3.blocks.7.layernorm_after.bias.bias', 'encoder.layers.3.blocks.7.attention.self.value.weight', 'encoder.layers.3.blocks.5.attention.self.query.bias', 'decoder.layers.2.blocks.5.attention.output.dense.weight', 'encoder.layers.0.blocks.4.layernorm_after.bias.weight', 'encoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.1.blocks.4.layernorm_before.weight.bias', 'encoder.layers.0.blocks.6.attention.self.key.weight', 'encoder.layers.0.blocks.4.attention.output.dense.weight', 'decoder.layers.0.blocks.4.layernorm_before.bias.weight', 'encoder.layers.0.blocks.5.intermediate.dense.weight', 'encoder.layers.2.blocks.4.attention.self.value.weight', 'encoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.4.layernorm_after.bias.weight', 'decoder.layers.0.blocks.4.layernorm_after.weight.bias', 'decoder.layers.2.blocks.7.layernorm_after.weight.bias', 'decoder.layers.1.blocks.4.attention.self.key.weight', 'decoder.layers.2.blocks.6.attention.output.dense.weight', 'encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.0.blocks.5.attention.output.dense.bias', 'decoder.layers.0.blocks.6.intermediate.dense.bias', 'decoder.layers.3.blocks.5.output.dense.weight', 'encoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.2.blocks.4.attention.self.logit_scale', 'decoder.layers.2.blocks.4.layernorm_before.bias.bias', 'encoder.layers.1.blocks.6.layernorm_after.weight.weight', 'encoder.layers.3.blocks.4.attention.self.value.weight', 'decoder.layers.0.blocks.7.attention.self.value.weight', 'decoder.layers.1.blocks.7.layernorm_after.bias.weight', 'encoder.layers.1.blocks.7.layernorm_after.bias.bias', 'encoder.layers.0.blocks.5.layernorm_after.weight.bias', 'encoder.layers.0.blocks.5.layernorm_after.bias.bias', 'decoder.layers.3.blocks.6.attention.self.query.weight', 'decoder.layers.3.blocks.7.attention.self.key.weight', 'decoder.layers.1.blocks.5.attention.self.key.weight', 'encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.1.blocks.4.layernorm_after.bias.weight', 'encoder.layers.3.blocks.4.layernorm_before.weight.weight', 'encoder.layers.2.blocks.6.attention.self.logit_scale', 'decoder.layers.3.blocks.5.attention.self.value.bias', 'encoder.layers.3.blocks.6.layernorm_before.weight.bias', 'decoder.layers.2.blocks.7.intermediate.dense.weight', 'encoder.layers.2.blocks.7.layernorm_before.weight.weight', 'encoder.layers.2.blocks.7.layernorm_after.bias.bias', 'decoder.layers.0.blocks.6.layernorm_after.bias.weight', 'encoder.layers.0.blocks.4.intermediate.dense.bias', 'encoder.layers.2.blocks.5.layernorm_after.weight.bias', 'decoder.layers.2.blocks.6.layernorm_after.bias.weight', 'encoder.layers.1.blocks.6.intermediate.dense.bias', 'decoder.layers.1.blocks.7.layernorm_before.bias.bias', 'decoder.layers.0.blocks.4.layernorm_before.weight.bias', 'decoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.3.blocks.4.attention.self.query.weight', 'decoder.layers.2.blocks.5.layernorm_after.weight.bias', 'decoder.layers.2.blocks.7.attention.self.logit_scale', 'encoder.layers.3.blocks.7.layernorm_before.weight.bias', 'decoder.layers.0.blocks.4.attention.self.query.bias', 'encoder.layers.3.blocks.5.attention.self.logit_scale', 'encoder.layers.1.blocks.7.layernorm_before.weight.bias', 'decoder.layers.3.blocks.4.output.dense.bias', 'decoder.layers.0.blocks.7.layernorm_before.bias.weight', 'encoder.layers.0.blocks.4.output.dense.weight', 'decoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.3.blocks.5.layernorm_after.bias.weight', 'decoder.layers.1.blocks.5.layernorm_after.bias.weight', 'decoder.layers.0.blocks.6.attention.self.key.weight', 'decoder.layers.0.blocks.6.attention.self.logit_scale', 'encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.1.blocks.6.layernorm_before.weight.weight', 'decoder.layers.3.blocks.4.attention.output.dense.bias', 'encoder.layers.1.blocks.5.layernorm_before.bias.bias', 'decoder.layers.2.blocks.6.output.dense.weight', 'decoder.layers.1.blocks.7.attention.output.dense.bias', 'decoder.layers.3.blocks.6.attention.self.logit_scale', 'encoder.layers.3.blocks.4.layernorm_before.weight.bias', 'encoder.layers.0.blocks.7.layernorm_after.bias.weight', 'decoder.layers.2.blocks.5.intermediate.dense.bias', 'decoder.layers.2.blocks.7.attention.output.dense.weight', 'decoder.layers.3.blocks.5.intermediate.dense.bias', 'encoder.layers.2.blocks.6.attention.self.value.bias', 'encoder.layers.0.blocks.5.layernorm_after.weight.weight', 'encoder.layers.1.blocks.7.layernorm_before.bias.bias', 'decoder.layers.3.blocks.7.attention.self.query.weight', 'encoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.2.blocks.4.intermediate.dense.bias', 'encoder.layers.1.blocks.7.attention.output.dense.weight', 'decoder.layers.2.blocks.6.layernorm_before.weight.weight', 'encoder.layers.3.blocks.6.layernorm_after.bias.weight', 'encoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.0.blocks.6.layernorm_before.bias.weight', 'encoder.layers.1.blocks.6.layernorm_after.bias.bias', 'encoder.layers.3.blocks.4.attention.output.dense.bias', 'decoder.layers.1.blocks.6.layernorm_before.bias.bias', 'decoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.0.blocks.4.layernorm_before.bias.bias', 'encoder.layers.3.blocks.7.attention.output.dense.bias', 'decoder.layers.3.blocks.4.layernorm_after.bias.bias', 'decoder.layers.1.blocks.7.layernorm_after.weight.bias', 'encoder.layers.1.blocks.6.attention.output.dense.weight', 'encoder.layers.2.blocks.6.intermediate.dense.bias', 'decoder.layers.2.blocks.5.attention.self.key.weight', 'encoder.layers.2.blocks.7.layernorm_before.bias.bias', 'decoder.layers.1.blocks.7.output.dense.bias', 'decoder.layers.3.blocks.7.intermediate.dense.bias', 'decoder.layers.3.blocks.6.layernorm_before.weight.weight', 'decoder.layers.0.blocks.6.layernorm_after.weight.bias', 'decoder.layers.3.blocks.6.output.dense.weight', 'encoder.layers.2.blocks.6.attention.self.value.weight', 'decoder.layers.3.blocks.4.attention.self.value.weight', 'encoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.7.output.dense.bias', 'decoder.layers.3.blocks.6.layernorm_after.bias.bias', 'decoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.4.intermediate.dense.weight', 'decoder.layers.1.blocks.7.layernorm_before.weight.bias', 'decoder.layers.2.blocks.5.intermediate.dense.weight', 'decoder.layers.1.blocks.5.layernorm_after.weight.weight', 'decoder.layers.1.blocks.7.layernorm_before.weight.weight', 'encoder.layers.2.blocks.5.layernorm_before.bias.bias', 'encoder.layers.0.blocks.5.attention.output.dense.weight', 'decoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.5.intermediate.dense.bias', 'decoder.layers.0.blocks.6.output.dense.bias', 'decoder.layers.3.blocks.7.layernorm_before.weight.weight', 'encoder.layers.0.blocks.6.layernorm_before.weight.bias', 'decoder.layers.0.blocks.5.attention.self.query.weight', 'decoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.1.blocks.4.layernorm_after.bias.weight', 'decoder.layers.3.blocks.6.attention.output.dense.bias', 'decoder.layers.2.blocks.7.layernorm_before.weight.bias', 'decoder.layers.3.blocks.5.layernorm_after.bias.bias', 'decoder.layers.3.blocks.6.attention.self.key.weight', 'encoder.layers.2.blocks.4.layernorm_after.bias.bias', 'encoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.1.blocks.6.output.dense.bias', 'decoder.layers.1.blocks.4.attention.output.dense.weight', 'decoder.layers.2.blocks.4.attention.output.dense.weight', 'decoder.layers.3.blocks.7.attention.output.dense.bias', 'decoder.layers.2.blocks.4.attention.self.query.weight', 'encoder.layers.0.blocks.5.attention.self.query.weight', 'encoder.layers.1.blocks.4.attention.self.value.weight', 'decoder.layers.2.blocks.4.output.dense.bias', 'decoder.layers.1.blocks.7.layernorm_before.bias.weight', 'decoder.layers.1.blocks.5.attention.output.dense.bias', 'encoder.layers.3.blocks.4.attention.self.key.weight', 'encoder.layers.1.blocks.4.layernorm_after.bias.bias', 'encoder.layers.2.blocks.6.layernorm_before.bias.bias', 'encoder.layers.0.blocks.6.layernorm_after.bias.weight', 'decoder.layers.1.blocks.5.layernorm_before.weight.weight', 'decoder.layers.3.blocks.6.intermediate.dense.weight', 'decoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.4.layernorm_before.bias.weight', 'decoder.layers.2.blocks.5.layernorm_before.bias.bias', 'decoder.layers.2.blocks.6.output.dense.bias', 'decoder.layers.2.blocks.6.attention.self.query.weight', 'decoder.layers.1.blocks.7.attention.self.value.bias', 'encoder.layers.3.blocks.6.intermediate.dense.weight', 'decoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.2.blocks.4.layernorm_before.bias.weight', 'decoder.layers.0.blocks.7.layernorm_after.bias.bias', 'encoder.layers.0.blocks.5.layernorm_before.bias.weight', 'decoder.layers.2.blocks.5.layernorm_after.bias.weight', 'encoder.layers.1.blocks.7.output.dense.weight', 'decoder.layers.1.blocks.5.attention.self.value.bias', 'encoder.layers.2.blocks.6.layernorm_after.weight.weight', 'decoder.layers.3.blocks.5.layernorm_before.weight.bias', 'encoder.layers.0.blocks.7.layernorm_before.weight.bias', 'decoder.layers.0.blocks.7.attention.output.dense.bias', 'encoder.layers.2.blocks.7.attention.self.query.weight', 'decoder.layers.2.blocks.4.intermediate.dense.weight', 'decoder.layers.3.blocks.5.output.dense.bias', 'encoder.layers.2.blocks.4.attention.self.value.bias', 'decoder.layers.0.blocks.4.attention.self.key.weight', 'encoder.layers.2.blocks.6.layernorm_before.weight.bias', 'encoder.layers.0.blocks.5.attention.self.value.weight', 'encoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.3.blocks.4.attention.self.query.bias', 'encoder.layers.3.blocks.4.layernorm_after.weight.bias', 'encoder.layers.0.blocks.7.attention.self.value.weight', 'encoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.1.blocks.6.layernorm_before.bias.weight', 'encoder.layers.2.blocks.7.layernorm_before.weight.bias', 'decoder.layers.1.blocks.5.output.dense.bias', 'encoder.layers.2.blocks.7.layernorm_after.weight.weight', 'encoder.layers.0.blocks.4.attention.self.key.weight', 'encoder.layers.3.blocks.4.output.dense.weight', 'encoder.layers.2.blocks.4.attention.self.query.bias', 'encoder.layers.3.blocks.4.intermediate.dense.weight', 'encoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.2.blocks.6.attention.self.query.weight', 'encoder.layers.2.blocks.6.intermediate.dense.weight', 'decoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.2.blocks.6.attention.self.query.bias', 'encoder.layers.0.blocks.6.attention.self.query.bias', 'decoder.layers.1.blocks.6.layernorm_after.bias.weight', 'decoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.6.attention.self.value.bias', 'decoder.layers.0.blocks.7.attention.self.query.bias', 'decoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.4.attention.self.logit_scale', 'encoder.layers.2.blocks.5.layernorm_after.weight.weight', 'encoder.layers.1.blocks.5.layernorm_after.bias.weight', 'encoder.layers.2.blocks.5.intermediate.dense.weight', 'decoder.layers.3.blocks.4.output.dense.weight', 'encoder.layers.3.blocks.5.layernorm_before.bias.weight', 'encoder.layers.3.blocks.6.attention.self.key.weight', 'encoder.layers.0.blocks.4.layernorm_before.bias.bias', 'decoder.layers.2.blocks.5.output.dense.bias', 'encoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.4.attention.output.dense.bias', 'encoder.layers.3.blocks.7.output.dense.bias', 'encoder.layers.0.blocks.7.output.dense.weight', 'encoder.layers.1.blocks.4.attention.output.dense.bias', 'decoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.3.blocks.7.attention.self.key.weight', 'encoder.layers.2.blocks.4.layernorm_before.weight.weight', 'decoder.layers.1.blocks.4.attention.self.query.bias', 'decoder.layers.1.blocks.4.layernorm_before.bias.weight', 'encoder.layers.3.blocks.5.layernorm_after.weight.bias', 'decoder.layers.2.blocks.7.attention.self.key.weight', 'encoder.layers.0.blocks.4.attention.self.query.bias', 'encoder.layers.0.blocks.6.attention.self.value.bias', 'decoder.layers.2.blocks.5.attention.self.query.weight', 'decoder.layers.1.blocks.4.layernorm_before.bias.bias', 'encoder.layers.1.blocks.5.layernorm_after.weight.weight', 'encoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.6.attention.self.logit_scale', 'encoder.layers.0.blocks.6.layernorm_after.weight.weight', 'decoder.layers.1.blocks.4.attention.self.value.weight', 'decoder.layers.3.blocks.4.attention.self.query.weight', 'decoder.layers.1.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.2.blocks.5.intermediate.dense.bias', 'decoder.layers.0.blocks.7.intermediate.dense.weight', 'encoder.layers.1.blocks.5.attention.self.query.weight', 'encoder.layers.0.blocks.5.output.dense.weight', 'decoder.layers.2.blocks.6.layernorm_after.weight.bias', 'encoder.layers.3.blocks.5.attention.self.query.weight', 'encoder.layers.2.blocks.4.layernorm_after.bias.weight', 'decoder.layers.3.blocks.5.attention.output.dense.bias', 'encoder.layers.0.blocks.5.layernorm_before.bias.bias', 'encoder.layers.1.blocks.4.attention.self.query.bias', 'encoder.layers.3.blocks.5.output.dense.weight', 'encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.4.intermediate.dense.bias', 'encoder.layers.3.blocks.5.attention.output.dense.weight', 'encoder.layers.0.blocks.4.layernorm_after.weight.weight', 'encoder.layers.1.blocks.7.output.dense.bias', 'decoder.layers.2.blocks.4.output.dense.weight', 'encoder.layers.2.blocks.4.intermediate.dense.bias', 'decoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.2.blocks.4.layernorm_after.bias.bias', 'encoder.layers.3.blocks.4.attention.self.logit_scale', 'encoder.layers.2.blocks.6.attention.self.query.bias', 'encoder.layers.2.blocks.7.layernorm_after.bias.weight', 'decoder.layers.3.blocks.7.layernorm_before.bias.bias', 'decoder.layers.1.blocks.6.layernorm_before.weight.bias', 'decoder.layers.0.blocks.7.layernorm_before.weight.bias', 'decoder.layers.2.blocks.6.layernorm_before.bias.bias', 'decoder.layers.3.blocks.4.layernorm_before.bias.bias', 'decoder.layers.2.blocks.7.layernorm_after.bias.bias', 'decoder.layers.0.blocks.5.layernorm_before.weight.bias', 'encoder.layers.2.blocks.4.attention.output.dense.bias', 'encoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.3.blocks.5.attention.self.key.weight', 'encoder.layers.3.blocks.6.output.dense.bias', 'encoder.layers.1.blocks.6.attention.self.query.weight', 'decoder.layers.0.blocks.7.layernorm_before.weight.weight', 'encoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.7.attention.output.dense.bias', 'encoder.layers.1.blocks.6.layernorm_before.bias.bias', 'decoder.layers.0.blocks.5.layernorm_before.bias.bias', 'encoder.layers.0.blocks.7.layernorm_after.weight.weight', 'encoder.layers.0.blocks.6.layernorm_after.bias.bias', 'encoder.layers.3.blocks.6.attention.self.query.bias', 'decoder.layers.2.blocks.7.layernorm_after.bias.weight', 'decoder.layers.0.blocks.7.output.dense.bias', 'encoder.layers.3.blocks.7.layernorm_after.bias.bias', 'encoder.layers.2.blocks.6.output.dense.bias', 'decoder.layers.2.blocks.7.layernorm_before.weight.weight', 'encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.1.blocks.7.layernorm_after.weight.weight', 'encoder.layers.0.blocks.6.attention.output.dense.bias', 'decoder.layers.1.blocks.6.attention.self.query.weight', 'encoder.layers.1.blocks.5.layernorm_after.bias.bias', 'decoder.layers.3.blocks.7.attention.self.query.bias', 'decoder.layers.3.blocks.5.layernorm_after.bias.weight', 'encoder.layers.2.blocks.5.layernorm_before.bias.weight', 'decoder.layers.3.blocks.4.attention.self.logit_scale', 'decoder.layers.3.blocks.4.attention.self.key.weight', 'encoder.layers.3.blocks.6.attention.output.dense.weight', 'decoder.layers.3.blocks.6.layernorm_after.weight.bias', 'encoder.layers.0.blocks.4.layernorm_before.weight.weight', 'decoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.7.attention.self.logit_scale', 'encoder.layers.3.blocks.4.layernorm_after.bias.bias', 'encoder.layers.0.blocks.6.output.dense.weight', 'encoder.layers.1.blocks.4.attention.output.dense.weight', 'encoder.layers.3.blocks.5.layernorm_before.bias.bias', 'decoder.layers.1.blocks.5.layernorm_before.bias.bias', 'encoder.layers.2.blocks.6.layernorm_before.weight.weight', 'decoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.2.blocks.7.attention.self.query.weight', 'decoder.layers.0.blocks.4.attention.self.value.weight', 'decoder.layers.0.blocks.6.attention.self.value.weight', 'decoder.layers.2.blocks.4.layernorm_after.weight.bias', 'encoder.layers.3.blocks.7.intermediate.dense.bias', 'encoder.layers.2.blocks.7.attention.self.value.weight', 'encoder.layers.3.blocks.7.layernorm_after.weight.bias', 'decoder.layers.3.blocks.6.attention.output.dense.weight', 'decoder.layers.2.blocks.6.layernorm_after.weight.weight', 'encoder.layers.2.blocks.5.attention.self.query.bias', 'encoder.layers.1.blocks.5.attention.self.query.bias', 'encoder.layers.1.blocks.4.output.dense.weight', 'encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.2.blocks.6.layernorm_before.bias.weight', 'decoder.layers.0.blocks.5.layernorm_after.weight.weight', 'decoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.0.blocks.7.attention.self.query.weight', 'encoder.layers.0.blocks.5.attention.self.query.bias', 'decoder.layers.3.blocks.7.layernorm_before.weight.bias', 'decoder.layers.0.blocks.6.layernorm_after.weight.weight', 'decoder.layers.2.blocks.6.attention.self.value.bias', 'encoder.layers.3.blocks.5.layernorm_after.weight.weight', 'decoder.layers.3.blocks.4.layernorm_before.weight.weight', 'decoder.layers.1.blocks.7.attention.self.value.weight', 'encoder.layers.3.blocks.7.attention.self.query.bias', 'decoder.layers.1.blocks.7.attention.output.dense.weight', 'encoder.layers.2.blocks.7.attention.self.key.weight', 'decoder.layers.2.blocks.7.output.dense.bias', 'encoder.layers.2.blocks.5.layernorm_before.weight.weight', 'encoder.layers.1.blocks.7.layernorm_before.bias.weight', 'encoder.layers.3.blocks.5.layernorm_before.weight.bias', 'encoder.layers.0.blocks.7.intermediate.dense.bias', 'encoder.layers.0.blocks.4.attention.self.value.weight', 'decoder.layers.0.blocks.6.attention.output.dense.weight', 'encoder.layers.1.blocks.4.layernorm_after.weight.weight', 'decoder.layers.1.blocks.5.layernorm_before.weight.bias', 'decoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.5.attention.output.dense.weight', 'decoder.layers.0.blocks.4.attention.self.logit_scale', 'encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.7.attention.self.logit_scale', 'encoder.layers.0.blocks.6.intermediate.dense.weight', 'encoder.layers.3.blocks.6.attention.self.query.weight', 'decoder.layers.3.blocks.5.attention.self.query.bias', 'encoder.layers.1.blocks.7.layernorm_after.weight.bias', 'encoder.layers.1.blocks.6.attention.output.dense.bias', 'decoder.layers.3.blocks.6.layernorm_before.bias.weight', 'decoder.layers.2.blocks.7.attention.self.value.weight', 'decoder.layers.3.blocks.5.attention.self.value.weight', 'encoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.1.blocks.5.layernorm_after.weight.bias', 'decoder.layers.2.blocks.4.attention.self.logit_scale', 'encoder.layers.1.blocks.6.attention.self.logit_scale', 'decoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.6.attention.self.value.weight', 'decoder.layers.1.blocks.7.attention.self.query.weight', 'decoder.layers.1.blocks.5.intermediate.dense.weight', 'encoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.1.blocks.7.intermediate.dense.bias', 'encoder.layers.0.blocks.7.attention.self.value.bias', 'encoder.layers.1.blocks.7.layernorm_after.bias.weight', 'decoder.layers.3.blocks.5.layernorm_before.bias.weight', 'decoder.layers.3.blocks.7.output.dense.bias', 'encoder.layers.3.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.0.blocks.7.attention.self.query.weight', 'decoder.layers.1.blocks.5.intermediate.dense.bias', 'encoder.layers.0.blocks.7.intermediate.dense.weight', 'decoder.layers.2.blocks.7.attention.self.query.bias', 'decoder.layers.0.blocks.4.layernorm_after.bias.bias', 'decoder.layers.1.blocks.5.attention.output.dense.weight', 'decoder.layers.3.blocks.4.attention.self.value.bias', 'encoder.layers.0.blocks.7.layernorm_before.bias.bias', 'decoder.layers.2.blocks.7.intermediate.dense.bias', 'encoder.layers.0.blocks.6.layernorm_before.bias.bias', 'encoder.layers.3.blocks.5.output.dense.bias', 'encoder.layers.1.blocks.5.layernorm_before.weight.weight', 'decoder.layers.2.blocks.7.layernorm_before.bias.bias', 'encoder.layers.0.blocks.5.attention.self.key.weight', 'decoder.layers.1.blocks.4.intermediate.dense.bias', 'decoder.layers.0.blocks.6.attention.self.value.bias', 'encoder.layers.3.blocks.4.attention.self.query.bias', 'decoder.layers.1.blocks.4.attention.self.logit_scale', 'decoder.layers.1.blocks.6.intermediate.dense.bias', 'encoder.layers.2.blocks.5.attention.self.value.bias', 'encoder.layers.0.blocks.4.output.dense.bias', 'encoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.4.layernorm_before.bias.weight', 'decoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.1.blocks.5.attention.self.value.weight', 'decoder.layers.2.blocks.7.attention.output.dense.bias', 'decoder.layers.1.blocks.4.attention.output.dense.bias', 'decoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.3.blocks.4.layernorm_before.weight.bias', 'encoder.layers.1.blocks.4.output.dense.bias', 'encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.3.blocks.6.output.dense.weight', 'decoder.layers.3.blocks.7.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.0.bias', 'encoder.layers.0.blocks.6.attention.self.value.weight', 'encoder.layers.2.blocks.7.layernorm_after.weight.bias', 'encoder.layers.1.blocks.6.attention.self.query.bias', 'decoder.layers.3.blocks.5.layernorm_after.weight.weight', 'decoder.layers.2.blocks.5.layernorm_before.bias.weight', 'decoder.layers.3.blocks.6.attention.self.value.weight', 'encoder.layers.1.blocks.4.intermediate.dense.weight', 'decoder.layers.3.blocks.7.attention.self.value.bias', 'decoder.layers.2.blocks.6.layernorm_before.weight.bias', 'decoder.layers.0.blocks.5.layernorm_after.weight.bias', 'decoder.layers.1.blocks.4.layernorm_after.weight.bias', 'decoder.layers.2.blocks.6.intermediate.dense.weight', 'encoder.layers.3.blocks.5.intermediate.dense.bias', 'decoder.layers.1.blocks.7.output.dense.weight', 'encoder.layers.3.blocks.4.layernorm_after.bias.weight', 'encoder.layers.2.blocks.5.layernorm_after.bias.weight', 'encoder.layers.0.blocks.5.layernorm_after.bias.weight', 'encoder.layers.1.blocks.6.output.dense.weight', 'decoder.layers.1.blocks.4.layernorm_after.bias.bias', 'decoder.layers.0.blocks.5.attention.self.query.bias', 'encoder.layers.2.blocks.7.intermediate.dense.bias', 'encoder.layers.3.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.3.blocks.5.intermediate.dense.weight', 'decoder.layers.0.blocks.4.output.dense.weight', 'decoder.layers.3.blocks.6.attention.self.query.bias', 'decoder.layers.1.blocks.4.attention.self.value.bias', 'decoder.layers.0.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.6.attention.output.dense.bias', 'decoder.layers.0.blocks.4.attention.output.dense.weight', 'decoder.layers.0.blocks.7.attention.self.logit_scale', 'encoder.layers.3.blocks.6.attention.self.value.bias', 'decoder.layers.2.blocks.5.output.dense.weight', 'encoder.layers.3.blocks.7.layernorm_after.weight.weight', 'decoder.layers.0.blocks.6.attention.self.query.weight', 'encoder.layers.0.blocks.7.layernorm_after.weight.bias', 'encoder.layers.3.blocks.6.attention.self.logit_scale', 'decoder.layers.2.blocks.4.attention.self.key.weight', 'decoder.layers.1.blocks.5.layernorm_before.bias.weight', 'decoder.layers.1.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.1.blocks.5.output.dense.weight', 'decoder.layers.0.blocks.4.attention.output.dense.bias', 'decoder.layers.0.blocks.5.output.dense.bias', 'encoder.layers.1.blocks.6.attention.self.value.bias', 'encoder.layers.0.blocks.4.layernorm_after.bias.bias', 'decoder.layers.3.blocks.4.attention.output.dense.weight', 'encoder.layers.1.blocks.4.attention.self.key.weight', 'decoder.layers.2.blocks.5.layernorm_after.weight.weight', 'decoder.layers.2.blocks.5.attention.self.query.bias', 'encoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'decoder.layers.0.blocks.7.intermediate.dense.bias', 'decoder.layers.2.blocks.6.intermediate.dense.bias', 'encoder.layers.0.blocks.7.layernorm_before.weight.weight', 'decoder.layers.0.blocks.5.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.6.layernorm_after.weight.bias', 'decoder.layers.0.blocks.7.layernorm_after.bias.weight', 'decoder.layers.0.blocks.4.attention.self.value.bias', 'decoder.layers.2.blocks.5.layernorm_after.bias.bias', 'decoder.layers.2.blocks.7.output.dense.weight', 'encoder.layers.0.blocks.6.layernorm_after.weight.bias', 'decoder.layers.0.blocks.7.attention.self.key.weight', 'decoder.layers.3.blocks.5.attention.self.key.weight', 'encoder.layers.1.blocks.6.output.dense.bias', 'decoder.layers.2.blocks.6.layernorm_after.bias.bias', 'encoder.layers.2.blocks.5.attention.output.dense.weight', 'encoder.layers.0.blocks.4.intermediate.dense.weight', 'decoder.layers.1.blocks.7.layernorm_after.bias.bias', 'decoder.layers.2.blocks.5.attention.output.dense.bias', 'decoder.layers.0.blocks.7.layernorm_after.weight.bias', 'decoder.layers.0.blocks.7.output.dense.weight', 'decoder.layers.0.blocks.5.layernorm_before.weight.weight', 'encoder.layers.1.blocks.7.attention.self.key.weight', 'encoder.layers.1.blocks.4.layernorm_before.bias.bias', 'encoder.layers.1.blocks.7.layernorm_before.weight.weight', 'encoder.layers.1.blocks.5.attention.self.value.weight', 'encoder.layers.3.blocks.7.output.dense.weight', 'encoder.layers.1.blocks.4.attention.self.query.weight', 'decoder.layers.0.blocks.4.intermediate.dense.weight', 'encoder.layers.3.blocks.5.intermediate.dense.weight', 'decoder.layers.1.blocks.6.attention.self.logit_scale', 'decoder.layers.1.blocks.4.output.dense.weight', 'encoder.layers.0.blocks.5.layernorm_before.weight.weight', 'encoder.layers.2.blocks.5.layernorm_after.bias.bias', 'encoder.layers.1.blocks.4.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.3.blocks.4.layernorm_before.bias.weight', 'decoder.layers.1.blocks.6.attention.output.dense.bias', 'decoder.layers.0.blocks.5.layernorm_after.bias.weight', 'decoder.layers.1.blocks.5.attention.self.query.bias', 'encoder.layers.3.blocks.7.intermediate.dense.weight', 'decoder.layers.2.blocks.5.attention.self.value.bias', 'decoder.layers.3.blocks.4.layernorm_after.bias.weight', 'encoder.layers.3.blocks.5.layernorm_before.weight.weight', 'encoder.layers.1.blocks.5.intermediate.dense.weight', 'encoder.layers.3.blocks.4.layernorm_after.weight.weight', 'decoder.layers.3.blocks.5.layernorm_before.weight.weight', 'encoder.layers.1.blocks.7.intermediate.dense.bias', 'decoder.layers.0.blocks.5.attention.self.key.weight', 'decoder.layers.0.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.3.blocks.7.layernorm_after.bias.weight', 'decoder.layers.0.blocks.5.attention.self.value.weight', 'decoder.layers.3.blocks.6.layernorm_after.bias.weight', 'encoder.layers.0.blocks.7.attention.self.logit_scale', 'encoder.layers.3.blocks.7.attention.self.logit_scale', 'decoder.layers.1.blocks.6.layernorm_after.bias.bias', 'decoder.layers.0.blocks.7.attention.self.continuous_position_bias_mlp.2.weight', 'decoder.layers.0.blocks.6.layernorm_after.bias.bias', 'decoder.layers.0.blocks.4.layernorm_before.weight.weight', 'encoder.layers.2.blocks.5.output.dense.bias', 'encoder.layers.3.blocks.6.attention.self.continuous_position_bias_mlp.0.weight', 'encoder.layers.1.blocks.6.layernorm_before.weight.bias', 'encoder.layers.0.blocks.7.attention.self.key.weight', 'decoder.layers.1.blocks.6.attention.self.value.bias', 'encoder.layers.1.blocks.4.attention.self.value.bias', 'decoder.layers.0.blocks.7.layernorm_before.bias.bias', 'encoder.layers.3.blocks.6.layernorm_before.bias.bias', 'decoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.1.blocks.4.intermediate.dense.bias', 'decoder.layers.2.blocks.4.attention.self.query.bias', 'encoder.layers.1.blocks.5.attention.output.dense.weight', 'decoder.layers.1.blocks.6.attention.self.query.bias', 'encoder.layers.2.blocks.7.attention.self.value.bias', 'encoder.layers.1.blocks.7.attention.self.value.bias', 'decoder.layers.1.blocks.5.layernorm_after.weight.bias', 'encoder.layers.2.blocks.6.output.dense.weight', 'decoder.layers.1.blocks.6.attention.self.continuous_position_bias_mlp.0.bias', 'decoder.layers.3.blocks.5.layernorm_before.bias.bias', 'decoder.layers.2.blocks.6.layernorm_before.bias.weight', 'encoder.layers.0.blocks.7.layernorm_after.bias.bias', 'encoder.layers.2.blocks.4.output.dense.bias', 'encoder.layers.3.blocks.7.layernorm_after.bias.weight', 'encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.2.weight', 'encoder.layers.1.blocks.7.intermediate.dense.weight', 'decoder.layers.0.blocks.6.intermediate.dense.weight', 'decoder.layers.2.blocks.6.attention.self.value.weight', 'decoder.layers.1.blocks.5.attention.self.logit_scale', 'decoder.layers.2.blocks.7.layernorm_before.bias.weight', 'decoder.layers.3.blocks.6.layernorm_before.bias.bias', 'encoder.layers.1.blocks.5.output.dense.weight', 'encoder.layers.1.blocks.5.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ScOT were not initialized from the model checkpoint at camlab-ethz/Poseidon-T and are newly initialized because the shapes did not match:
- decoder.layers.0.blocks.0.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.0.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- decoder.layers.0.blocks.0.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.0.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.0.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- decoder.layers.0.blocks.1.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.1.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- decoder.layers.0.blocks.1.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.1.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.1.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- decoder.layers.0.blocks.2.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.2.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- decoder.layers.0.blocks.2.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.2.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.2.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- decoder.layers.0.blocks.3.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- decoder.layers.0.blocks.3.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- decoder.layers.0.blocks.3.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- decoder.layers.0.blocks.3.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.0.blocks.3.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- decoder.layers.0.upsample.mixup.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.0.upsample.norm.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.0.upsample.norm.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.0.upsample.norm.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.0.upsample.norm.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.0.upsample.upsample.weight: found shape torch.Size([768, 384]) in the checkpoint and torch.Size([1536, 768]) in the model instantiated
- decoder.layers.1.blocks.0.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.0.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- decoder.layers.1.blocks.0.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.0.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.0.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- decoder.layers.1.blocks.1.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.1.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- decoder.layers.1.blocks.1.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.1.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.1.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- decoder.layers.1.blocks.2.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.2.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- decoder.layers.1.blocks.2.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.2.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.2.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- decoder.layers.1.blocks.3.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- decoder.layers.1.blocks.3.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- decoder.layers.1.blocks.3.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- decoder.layers.1.blocks.3.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.1.blocks.3.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- decoder.layers.1.upsample.mixup.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.1.upsample.norm.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.1.upsample.norm.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.1.upsample.norm.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.1.upsample.norm.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.1.upsample.upsample.weight: found shape torch.Size([384, 192]) in the checkpoint and torch.Size([768, 384]) in the model instantiated
- decoder.layers.2.blocks.0.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.0.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.2.blocks.0.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.0.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.0.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- decoder.layers.2.blocks.1.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.1.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.2.blocks.1.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.1.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.1.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- decoder.layers.2.blocks.2.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.2.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.2.blocks.2.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.2.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.2.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- decoder.layers.2.blocks.3.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- decoder.layers.2.blocks.3.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- decoder.layers.2.blocks.3.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- decoder.layers.2.blocks.3.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- decoder.layers.2.blocks.3.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- decoder.layers.2.upsample.mixup.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.2.upsample.norm.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.2.upsample.norm.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.2.upsample.norm.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.2.upsample.norm.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.2.upsample.upsample.weight: found shape torch.Size([192, 96]) in the checkpoint and torch.Size([384, 192]) in the model instantiated
- decoder.layers.3.blocks.0.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.0.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.3.blocks.0.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.0.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.0.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- decoder.layers.3.blocks.1.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.1.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.3.blocks.1.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.1.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.1.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- decoder.layers.3.blocks.2.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.2.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.3.blocks.2.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.2.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.2.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- decoder.layers.3.blocks.3.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- decoder.layers.3.blocks.3.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- decoder.layers.3.blocks.3.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- decoder.layers.3.blocks.3.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- decoder.layers.3.blocks.3.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- embeddings.norm.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- embeddings.norm.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- embeddings.norm.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- embeddings.norm.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- embeddings.patch_embeddings.projection.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- embeddings.patch_embeddings.projection.weight: found shape torch.Size([48, 4, 4, 4]) in the checkpoint and torch.Size([96, 3, 4, 4]) in the model instantiated
- encoder.layers.0.blocks.0.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.0.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.0.blocks.0.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.0.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.0.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- encoder.layers.0.blocks.1.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.1.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.0.blocks.1.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.1.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.1.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- encoder.layers.0.blocks.2.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.2.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.0.blocks.2.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.2.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.2.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- encoder.layers.0.blocks.3.attention.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.output.dense.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.self.key.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.self.query.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.self.query.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.self.value.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.attention.self.value.weight: found shape torch.Size([48, 48]) in the checkpoint and torch.Size([96, 96]) in the model instantiated
- encoder.layers.0.blocks.3.intermediate.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.0.blocks.3.intermediate.dense.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_after.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_after.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_after.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_after.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_before.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_before.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_before.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.layernorm_before.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- encoder.layers.0.blocks.3.output.dense.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- encoder.layers.0.blocks.3.output.dense.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- encoder.layers.0.downsample.norm.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.0.downsample.norm.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.0.downsample.norm.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.0.downsample.norm.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.0.downsample.reduction.weight: found shape torch.Size([96, 192]) in the checkpoint and torch.Size([192, 384]) in the model instantiated
- encoder.layers.1.blocks.0.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.0.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.1.blocks.0.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.0.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.0.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- encoder.layers.1.blocks.1.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.1.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.1.blocks.1.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.1.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.1.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- encoder.layers.1.blocks.2.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.2.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.1.blocks.2.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.2.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.2.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- encoder.layers.1.blocks.3.attention.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.output.dense.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.self.key.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.self.query.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.self.query.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.self.value.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.attention.self.value.weight: found shape torch.Size([96, 96]) in the checkpoint and torch.Size([192, 192]) in the model instantiated
- encoder.layers.1.blocks.3.intermediate.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.1.blocks.3.intermediate.dense.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_after.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_after.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_after.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_after.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_before.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_before.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_before.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.layernorm_before.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- encoder.layers.1.blocks.3.output.dense.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- encoder.layers.1.blocks.3.output.dense.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- encoder.layers.1.downsample.norm.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.1.downsample.norm.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.1.downsample.norm.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.1.downsample.norm.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.1.downsample.reduction.weight: found shape torch.Size([192, 384]) in the checkpoint and torch.Size([384, 768]) in the model instantiated
- encoder.layers.2.blocks.0.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.0.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- encoder.layers.2.blocks.0.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.0.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.0.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- encoder.layers.2.blocks.1.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.1.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- encoder.layers.2.blocks.1.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.1.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.1.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- encoder.layers.2.blocks.2.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.2.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- encoder.layers.2.blocks.2.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.2.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.2.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- encoder.layers.2.blocks.3.attention.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.output.dense.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.self.key.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.self.query.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.self.query.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.self.value.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.attention.self.value.weight: found shape torch.Size([192, 192]) in the checkpoint and torch.Size([384, 384]) in the model instantiated
- encoder.layers.2.blocks.3.intermediate.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- encoder.layers.2.blocks.3.intermediate.dense.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_after.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_after.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_after.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_after.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_before.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_before.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_before.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.layernorm_before.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- encoder.layers.2.blocks.3.output.dense.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- encoder.layers.2.blocks.3.output.dense.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- encoder.layers.2.downsample.norm.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.2.downsample.norm.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.2.downsample.norm.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.2.downsample.norm.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.2.downsample.reduction.weight: found shape torch.Size([384, 768]) in the checkpoint and torch.Size([768, 1536]) in the model instantiated
- encoder.layers.3.blocks.0.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.0.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- encoder.layers.3.blocks.0.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.0.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.0.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- encoder.layers.3.blocks.1.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.1.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- encoder.layers.3.blocks.1.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.1.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.1.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- encoder.layers.3.blocks.2.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.2.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- encoder.layers.3.blocks.2.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.2.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.2.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- encoder.layers.3.blocks.3.attention.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.output.dense.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.self.key.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.self.query.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.self.query.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.self.value.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.attention.self.value.weight: found shape torch.Size([384, 384]) in the checkpoint and torch.Size([768, 768]) in the model instantiated
- encoder.layers.3.blocks.3.intermediate.dense.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([3072]) in the model instantiated
- encoder.layers.3.blocks.3.intermediate.dense.weight: found shape torch.Size([1536, 384]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_after.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_after.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_after.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_after.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_before.bias.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_before.bias.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_before.weight.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.layernorm_before.weight.weight: found shape torch.Size([384, 1]) in the checkpoint and torch.Size([768, 1]) in the model instantiated
- encoder.layers.3.blocks.3.output.dense.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- encoder.layers.3.blocks.3.output.dense.weight: found shape torch.Size([384, 1536]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated
- patch_recovery.mixup.weight: found shape torch.Size([4, 4, 5, 5]) in the checkpoint and torch.Size([3, 3, 5, 5]) in the model instantiated
- patch_recovery.projection.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([3]) in the model instantiated
- patch_recovery.projection.weight: found shape torch.Size([48, 4, 4, 4]) in the checkpoint and torch.Size([96, 3, 4, 4]) in the model instantiated
- residual_blocks.0.0.dwconv.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.0.dwconv.weight: found shape torch.Size([48, 1, 7, 7]) in the checkpoint and torch.Size([96, 1, 7, 7]) in the model instantiated
- residual_blocks.0.0.norm.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.0.norm.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- residual_blocks.0.0.norm.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.0.norm.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- residual_blocks.0.0.pwconv1.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.0.0.pwconv1.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- residual_blocks.0.0.pwconv2.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.0.pwconv2.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- residual_blocks.0.0.weight: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.1.dwconv.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.1.dwconv.weight: found shape torch.Size([48, 1, 7, 7]) in the checkpoint and torch.Size([96, 1, 7, 7]) in the model instantiated
- residual_blocks.0.1.norm.bias.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.1.norm.bias.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- residual_blocks.0.1.norm.weight.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.1.norm.weight.weight: found shape torch.Size([48, 1]) in the checkpoint and torch.Size([96, 1]) in the model instantiated
- residual_blocks.0.1.pwconv1.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.0.1.pwconv1.weight: found shape torch.Size([192, 48]) in the checkpoint and torch.Size([384, 96]) in the model instantiated
- residual_blocks.0.1.pwconv2.bias: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.0.1.pwconv2.weight: found shape torch.Size([48, 192]) in the checkpoint and torch.Size([96, 384]) in the model instantiated
- residual_blocks.0.1.weight: found shape torch.Size([48]) in the checkpoint and torch.Size([96]) in the model instantiated
- residual_blocks.1.0.dwconv.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.0.dwconv.weight: found shape torch.Size([96, 1, 7, 7]) in the checkpoint and torch.Size([192, 1, 7, 7]) in the model instantiated
- residual_blocks.1.0.norm.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.0.norm.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- residual_blocks.1.0.norm.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.0.norm.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- residual_blocks.1.0.pwconv1.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- residual_blocks.1.0.pwconv1.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- residual_blocks.1.0.pwconv2.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.0.pwconv2.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- residual_blocks.1.0.weight: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.1.dwconv.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.1.dwconv.weight: found shape torch.Size([96, 1, 7, 7]) in the checkpoint and torch.Size([192, 1, 7, 7]) in the model instantiated
- residual_blocks.1.1.norm.bias.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.1.norm.bias.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- residual_blocks.1.1.norm.weight.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.1.norm.weight.weight: found shape torch.Size([96, 1]) in the checkpoint and torch.Size([192, 1]) in the model instantiated
- residual_blocks.1.1.pwconv1.bias: found shape torch.Size([384]) in the checkpoint and torch.Size([768]) in the model instantiated
- residual_blocks.1.1.pwconv1.weight: found shape torch.Size([384, 96]) in the checkpoint and torch.Size([768, 192]) in the model instantiated
- residual_blocks.1.1.pwconv2.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.1.1.pwconv2.weight: found shape torch.Size([96, 384]) in the checkpoint and torch.Size([192, 768]) in the model instantiated
- residual_blocks.1.1.weight: found shape torch.Size([96]) in the checkpoint and torch.Size([192]) in the model instantiated
- residual_blocks.2.0.dwconv.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.0.dwconv.weight: found shape torch.Size([192, 1, 7, 7]) in the checkpoint and torch.Size([384, 1, 7, 7]) in the model instantiated
- residual_blocks.2.0.norm.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.0.norm.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- residual_blocks.2.0.norm.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.0.norm.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- residual_blocks.2.0.pwconv1.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- residual_blocks.2.0.pwconv1.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- residual_blocks.2.0.pwconv2.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.0.pwconv2.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- residual_blocks.2.0.weight: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.1.dwconv.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.1.dwconv.weight: found shape torch.Size([192, 1, 7, 7]) in the checkpoint and torch.Size([384, 1, 7, 7]) in the model instantiated
- residual_blocks.2.1.norm.bias.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.1.norm.bias.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- residual_blocks.2.1.norm.weight.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.1.norm.weight.weight: found shape torch.Size([192, 1]) in the checkpoint and torch.Size([384, 1]) in the model instantiated
- residual_blocks.2.1.pwconv1.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([1536]) in the model instantiated
- residual_blocks.2.1.pwconv1.weight: found shape torch.Size([768, 192]) in the checkpoint and torch.Size([1536, 384]) in the model instantiated
- residual_blocks.2.1.pwconv2.bias: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
- residual_blocks.2.1.pwconv2.weight: found shape torch.Size([192, 768]) in the checkpoint and torch.Size([384, 1536]) in the model instantiated
- residual_blocks.2.1.weight: found shape torch.Size([192]) in the checkpoint and torch.Size([384]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: Currently logged in as: rohanvk (rohanvk-carnegie-mellon-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.20.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /home/rvk/wandb/run-20250610_204852-98pdqfgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-fog-3
wandb:  View project at https://wandb.ai/rohanvk-carnegie-mellon-university/pos
wandb:  View run at https://wandb.ai/rohanvk-carnegie-mellon-university/pos/runs/98pdqfgx
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [01:17<2:07:31, 77.29s/it]  2%|         | 2/100 [02:34<2:06:33, 77.49s/it]  3%|         | 3/100 [03:47<2:01:39, 75.25s/it]  4%|         | 4/100 [05:04<2:01:12, 75.76s/it]  5%|         | 5/100 [06:22<2:01:28, 76.72s/it]  6%|         | 6/100 [07:38<1:59:39, 76.38s/it]  7%|         | 7/100 [08:51<1:56:50, 75.39s/it]  8%|         | 8/100 [10:08<1:56:07, 75.74s/it]  9%|         | 9/100 [11:20<1:53:29, 74.83s/it] 10%|         | 10/100 [12:31<1:50:30, 73.67s/it] 11%|         | 11/100 [13:38<1:46:10, 71.58s/it] 12%|        | 12/100 [14:43<1:41:51, 69.45s/it] 13%|        | 13/100 [15:54<1:41:15, 69.83s/it] 14%|        | 14/100 [17:10<1:43:02, 71.88s/it] 15%|        | 15/100 [18:26<1:43:39, 73.17s/it] 16%|        | 16/100 [19:41<1:43:01, 73.58s/it] 17%|        | 17/100 [20:58<1:43:11, 74.60s/it] 18%|        | 18/100 [22:15<1:43:12, 75.52s/it] 19%|        | 19/100 [23:32<1:42:28, 75.90s/it] 20%|        | 20/100 [24:47<1:40:53, 75.67s/it] 21%|        | 21/100 [26:02<1:39:22, 75.48s/it] 22%|       | 22/100 [27:16<1:37:31, 75.02s/it] 23%|       | 23/100 [28:26<1:34:14, 73.43s/it] 24%|       | 24/100 [29:31<1:29:51, 70.95s/it] 25%|       | 25/100 [30:36<1:26:13, 68.98s/it] 26%|       | 26/100 [31:40<1:23:21, 67.59s/it] 27%|       | 27/100 [32:45<1:21:22, 66.89s/it] 28%|       | 28/100 [33:50<1:19:23, 66.16s/it] 29%|       | 29/100 [34:54<1:17:37, 65.60s/it] 30%|       | 30/100 [35:58<1:16:06, 65.24s/it] 31%|       | 31/100 [37:04<1:15:00, 65.22s/it] 32%|      | 32/100 [38:08<1:13:47, 65.10s/it] 33%|      | 33/100 [39:12<1:12:18, 64.75s/it] 34%|      | 34/100 [40:17<1:11:04, 64.61s/it] 35%|      | 35/100 [41:21<1:09:54, 64.53s/it] 36%|      | 36/100 [42:26<1:08:56, 64.63s/it] 37%|      | 37/100 [43:30<1:07:47, 64.57s/it] 38%|      | 38/100 [44:35<1:06:43, 64.57s/it] 39%|      | 39/100 [45:40<1:05:46, 64.70s/it] 40%|      | 40/100 [46:44<1:04:34, 64.58s/it] 41%|      | 41/100 [47:49<1:03:36, 64.68s/it] 42%|     | 42/100 [48:54<1:02:39, 64.82s/it] 43%|     | 43/100 [49:59<1:01:39, 64.91s/it] 44%|     | 44/100 [51:05<1:00:48, 65.15s/it] 45%|     | 45/100 [52:09<59:29, 64.89s/it]   46%|     | 46/100 [53:14<58:24, 64.90s/it] 47%|     | 47/100 [54:19<57:11, 64.75s/it] 48%|     | 48/100 [55:23<56:05, 64.72s/it] 49%|     | 49/100 [56:28<54:58, 64.68s/it] 50%|     | 50/100 [57:32<53:47, 64.56s/it] 51%|     | 51/100 [58:37<52:52, 64.74s/it] 52%|    | 52/100 [59:43<52:08, 65.17s/it] 53%|    | 53/100 [1:00:47<50:44, 64.79s/it] 54%|    | 54/100 [1:01:52<49:36, 64.72s/it] 55%|    | 55/100 [1:02:57<48:31, 64.70s/it] 56%|    | 56/100 [1:04:01<47:24, 64.66s/it] 57%|    | 57/100 [1:05:06<46:23, 64.72s/it] 58%|    | 58/100 [1:06:11<45:25, 64.88s/it] 59%|    | 59/100 [1:07:16<44:17, 64.82s/it] 60%|    | 60/100 [1:08:21<43:09, 64.73s/it] 61%|    | 61/100 [1:09:25<42:03, 64.70s/it] 62%|   | 62/100 [1:10:30<40:56, 64.64s/it] 63%|   | 63/100 [1:11:34<39:45, 64.46s/it] 64%|   | 64/100 [1:12:39<38:45, 64.60s/it] 65%|   | 65/100 [1:13:43<37:40, 64.58s/it] 66%|   | 66/100 [1:14:48<36:33, 64.53s/it] 67%|   | 67/100 [1:15:52<35:28, 64.50s/it] 68%|   | 68/100 [1:16:57<34:25, 64.55s/it] 69%|   | 69/100 [1:18:01<33:19, 64.49s/it] 70%|   | 70/100 [1:19:07<32:25, 64.85s/it] 71%|   | 71/100 [1:20:12<31:23, 64.95s/it] 72%|  | 72/100 [1:21:17<30:21, 65.04s/it] 73%|  | 73/100 [1:22:22<29:13, 64.95s/it] 74%|  | 74/100 [1:23:27<28:08, 64.94s/it] 75%|  | 75/100 [1:24:32<27:04, 64.99s/it] 76%|  | 76/100 [1:25:37<26:01, 65.06s/it] 77%|  | 77/100 [1:26:42<24:55, 65.03s/it] 78%|  | 78/100 [1:27:48<23:54, 65.21s/it] 79%|  | 79/100 [1:28:53<22:49, 65.21s/it] 80%|  | 80/100 [1:29:58<21:43, 65.16s/it] 81%|  | 81/100 [1:31:03<20:39, 65.23s/it] 82%| | 82/100 [1:32:08<19:32, 65.14s/it] 83%| | 83/100 [1:33:14<18:29, 65.26s/it] 84%| | 84/100 [1:34:19<17:21, 65.10s/it] 85%| | 85/100 [1:35:24<16:16, 65.11s/it] 86%| | 86/100 [1:36:29<15:13, 65.26s/it] 87%| | 87/100 [1:37:34<14:06, 65.11s/it] 88%| | 88/100 [1:38:40<13:03, 65.29s/it] 89%| | 89/100 [1:39:45<11:59, 65.38s/it] 90%| | 90/100 [1:40:51<10:54, 65.48s/it] 91%| | 91/100 [1:41:55<09:45, 65.06s/it] 92%|| 92/100 [1:43:01<08:41, 65.19s/it] 93%|| 93/100 [1:44:07<07:38, 65.52s/it] 94%|| 94/100 [1:45:12<06:33, 65.51s/it] 95%|| 95/100 [1:46:17<05:26, 65.27s/it] 96%|| 96/100 [1:47:22<04:20, 65.09s/it] 97%|| 97/100 [1:48:27<03:14, 64.99s/it] 98%|| 98/100 [1:49:31<02:09, 64.71s/it] 99%|| 99/100 [1:50:35<01:04, 64.64s/it]100%|| 100/100 [1:51:40<00:00, 64.61s/it]100%|| 100/100 [1:51:40<00:00, 67.00s/it]
Error executing job with overrides: ['model=pos/pos', 'dataset=navier_stokes/ns_512_0']
Traceback (most recent call last):
  File "/home/rvk/pos_main.py", line 137, in main
    avg_l2_loss = pos_evaluate(model, test_loader, y_normalizer, args.dataset.pde, job_id)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rvk/train/training.py", line 298, in pos_evaluate
    time_val = torch.tensor([time])
               ^^^^^^^^^^^^^^^^^^^^
ValueError: too many dimensions 'str'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:      epoch 
wandb: train_loss 
wandb:   val_loss 
wandb: 
wandb: Run summary:
wandb:      epoch 99
wandb: train_loss 0.08688
wandb:   val_loss 0.08757
wandb: 
wandb:  View run vivid-fog-3 at: https://wandb.ai/rohanvk-carnegie-mellon-university/pos/runs/98pdqfgx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250610_204852-98pdqfgx/logs
srun: error: babel-0-31: task 0: Exited with exit code 1
