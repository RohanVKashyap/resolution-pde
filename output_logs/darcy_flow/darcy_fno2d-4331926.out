Job started on babel-5-19 at Tue Mar  4 16:53:44 EST 2025
Using device: cuda
Loading data from data/darcy_data_mat/piececonst_r241_N1024_smooth1.mat and data/darcy_data_mat/piececonst_r241_N1024_smooth2.mat
Loaded data shapes: X=(2048, 241, 241), y=(2048, 241, 241)
Training set: 1638 samples
Validation set: 204 samples
Test set: 206 samples
Input shape: torch.Size([64, 1, 241, 241])
Output shape: torch.Size([64, 1, 241, 241])
Epoch 0, Train Loss: 0.688939, Val Loss: 0.203510
Epoch 10, Train Loss: 0.012765, Val Loss: 0.014786
Epoch 20, Train Loss: 0.003563, Val Loss: 0.005374
Epoch 30, Train Loss: 0.002093, Val Loss: 0.003771
Epoch 40, Train Loss: 0.001534, Val Loss: 0.002969
Epoch 50, Train Loss: 0.001038, Val Loss: 0.002521
Epoch 60, Train Loss: 0.000823, Val Loss: 0.002209
Epoch 70, Train Loss: 0.000735, Val Loss: 0.003130
Epoch 80, Train Loss: 0.000609, Val Loss: 0.001864
Epoch 90, Train Loss: 0.000539, Val Loss: 0.001757
Epoch 100, Train Loss: 0.000468, Val Loss: 0.001750
Epoch 110, Train Loss: 0.000435, Val Loss: 0.001493
Epoch 120, Train Loss: 0.000399, Val Loss: 0.001413
Epoch 130, Train Loss: 0.000364, Val Loss: 0.001465
Epoch 140, Train Loss: 0.000345, Val Loss: 0.001434
Epoch 150, Train Loss: 0.000328, Val Loss: 0.001385
Epoch 160, Train Loss: 0.000316, Val Loss: 0.001380
Epoch 170, Train Loss: 0.000310, Val Loss: 0.001312
Epoch 180, Train Loss: 0.000304, Val Loss: 0.001244
Epoch 190, Train Loss: 0.000303, Val Loss: 0.001498
Test L2 Loss: 0.000209
Model saved to checkpoints/darcy_flow_fno2d/darcy_flow_fno2d.pt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33msolar-frog-1[0m at: [34mhttps://wandb.ai/rohanvk-carnegie-mellon-university/darcy_flow_fno2d/runs/lz70m9zx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250304_165403-lz70m9zx/logs[0m
Job completed at Tue Mar  4 17:19:37 EST 2025
