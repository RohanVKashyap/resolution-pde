Job started on babel-1-27 at Tue Apr 15 18:12:46 EDT 2025
Job ID: 4574823
Using device: cuda
[2025-04-15 18:12:50,728][root][INFO] - model:
  _target_: models.ffno.FFNO1D
  in_channels: 1
  out_channels: 1
  width: 32
  n_modes: 16
  factor: 4
  n_layers: 4
  ff_weight_norm: true
  n_ff_layers: 2
  layer_norm: false
  grid: null
  dropout: 0.0
  mode: full
dataset:
  reduced_batch: 1
  reduced_resolution: 4
  reduced_resolution_t: 4
  window_size: 15
  original_res: 1024
  pde: burger_2.0
  data_path1: data/pdebench/1D_Burgers_Sols_Nu2.0.hdf5
training:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: burger_2.0_ffno_1d/ffno_1d
Model name: models.ffno.FFNO1D
PDE Dataset: burger_2.0
Loading from file: /home/rvk/data/pdebench/1D_Burgers_Sols_Nu2.0.hdf5
(10000, 201, 1024)
Total data shape: (10000, 51, 256)
x shape: (490000, 1, 256)
y shape: (490000, 1, 256)
grid shape: torch.Size([256, 1])
---------Using data normalizer---------------
Train dataset size: 392000
Validation dataset size: 49000
Test dataset size: 49000
<class 'torch.Tensor'> 0.10502990335226059 0.10505521297454834 0.992267906665802 0.9925017952919006
Sample Input shape: torch.Size([64, 1, 256])
Sample Output shape: torch.Size([64, 1, 256])
FFNO1D(
  (in_proj): WNLinear(in_features=2, out_features=32, bias=True)
  (fourier_layers): ModuleList(
    (0-3): 4 x FSpectralConv1d(
      (fourier_weight): ParameterList(  (0): Parameter containing: [torch.float32 of size 32x32x16x2 (cuda:0)])
      (backcast_ff): FeedForward(
        (layers): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
            (3): Identity()
          )
          (1): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
            (1): Dropout(p=0.0, inplace=False)
            (2): Identity()
            (3): Identity()
          )
        )
      )
      (act): Identity()
    )
  )
  (out_proj): WNLinear(in_features=32, out_features=1, bias=True)
)
Epoch 0, Train Loss: 0.10165606, Val Loss: 0.01929584
Epoch 10, Train Loss: 0.00956107, Val Loss: 0.00777596
Epoch 20, Train Loss: 0.00760435, Val Loss: 0.00170041
Epoch 30, Train Loss: 0.00579537, Val Loss: 0.02327347
Epoch 40, Train Loss: 0.00478323, Val Loss: 0.00105838
Epoch 50, Train Loss: 0.00365676, Val Loss: 0.00122717
Epoch 60, Train Loss: 0.00210089, Val Loss: 0.00075159
Epoch 70, Train Loss: 0.00143816, Val Loss: 0.00114375
Epoch 80, Train Loss: 0.00067784, Val Loss: 0.00139591
Epoch 90, Train Loss: 0.00025203, Val Loss: 0.00016836
Test L2 Loss: 0.000115
-----Visualizing Saved------
Figure saved to output_logs/predictions/burger_2.0_fno_4574823_predictions.png
Model saved to checkpoints/ffno1d/burger_2.0_4574823.pt
Original test data shape: x=torch.Size([49000, 1, 256]), y=torch.Size([49000, 1, 256])

Evaluating at resolution factor: 1
Resolution factor 1 - Relative L2 Loss: 0.000115

Evaluating at resolution factor: 2
Downsampled shapes: x=torch.Size([49000, 1, 128]), y=torch.Size([49000, 1, 128])
Resolution factor 2 - Relative L2 Loss: 0.000384

Evaluating at resolution factor: 4
Downsampled shapes: x=torch.Size([49000, 1, 64]), y=torch.Size([49000, 1, 64])
Resolution factor 4 - Relative L2 Loss: 0.000386

Evaluating at resolution factor: 8
Downsampled shapes: x=torch.Size([49000, 1, 32]), y=torch.Size([49000, 1, 32])
Resolution factor 8 - Relative L2 Loss: 0.000407

Evaluating at resolution factor: 16
Downsampled shapes: x=torch.Size([49000, 1, 16]), y=torch.Size([49000, 1, 16])
Skipping Resolution factor 16 because not enough modes

Evaluating at resolution factor: 32
Downsampled shapes: x=torch.Size([49000, 1, 8]), y=torch.Size([49000, 1, 8])
Skipping Resolution factor 32 because not enough modes
Loading from file: /home/rvk/data/pdebench/1D_Burgers_Sols_Nu2.0.hdf5
(10000, 201, 1024)
Total data shape: (10000, 51, 1024)
x shape: (490000, 1, 1024)
y shape: (490000, 1, 1024)
grid shape: torch.Size([1024, 1])
---------Using data normalizer---------------
Train dataset size: 392000
Validation dataset size: 49000
Test dataset size: 49000
Original test data shape: x=torch.Size([49000, 1, 1024]), y=torch.Size([49000, 1, 1024])
Testing resolutions: [512, 1024]

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([49000, 1, 512]), y=torch.Size([49000, 1, 512])
Resolution 512 - Relative L2 Loss: 0.000384

Evaluating at resolution: 1024
Downsampled shapes: x=torch.Size([49000, 1, 1024]), y=torch.Size([49000, 1, 1024])
Resolution 1024 - Relative L2 Loss: 0.006691

Summary of Super-Resolution Evaluation:
Resolution factor 1: Relative L2 Loss = 0.000115
Resolution factor 2: Relative L2 Loss = 0.000384
Resolution factor 4: Relative L2 Loss = 0.000386
Resolution factor 8: Relative L2 Loss = 0.000407

Summary of Higher-Resolution Evaluation:
Resolution 512: Relative L2 Loss = 0.000384
Resolution 1024: Relative L2 Loss = 0.006691
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mcomic-vortex-83[0m at: [34mhttps://wandb.ai/rohanvk-carnegie-mellon-university/ffno1d/runs/20ztbwmh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250415_181309-20ztbwmh/logs[0m
Job completed at Tue Apr 15 19:59:37 EDT 2025
