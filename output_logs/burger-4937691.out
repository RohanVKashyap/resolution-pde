Job started on babel-5-27 at Mon May 26 03:37:49 EDT 2025
Job ID: 4937691
GPU information:
Mon May 26 03:37:49 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:41:00.0 Off |                    0 |
| N/A   37C    P0             57W /  270W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:61:00.0 Off |                    0 |
| N/A   34C    P0             54W /  270W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
CUDA devices:
CUDA_VISIBLE_DEVICES: 0,1
Using device: cuda
[2025-05-26 03:37:53,973][root][INFO] - model:
  _target_: models.s4_2d.S4NDModel
  d_input: 15
  d_output: 3
  d_model: 64
  n_layers: 4
  dropout: 0.2
  prenorm: false
dataset:
  reduced_batch: 1
  reduced_resolution: 2
  reduced_resolution_t: 1
  window_size: 15
  original_res: 512
  pde: navier_stokes_0
  data_path1: data/pdebench/ns_incom_inhom_2d_512-100.hdf5
training:
  batch_size: 4
  epochs: 100
  learning_rate: 0.001
  use_normalizer: false
project_name: ${dataset.pde}_${hydra:runtime.choices.model}
checkpoint_dir: checkpoints

Project name: navier_stokes_0_s4_2d/s4_2d
Model name: models.s4_2d.S4NDModel
PDE Dataset: navier_stokes_0
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 256, 256, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 256, 256, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> 0.0024212526623159647 -0.0016410896787419915 0.8589648604393005 0.8987521529197693
Sample Input shape: torch.Size([4, 45, 256, 256])
Sample Output shape: torch.Size([4, 3, 256, 256])
[2025-05-26 03:38:30,244][models.s4][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-26 03:38:30,245][models.s4][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
[2025-05-26 03:38:30,249][models.s4nd][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2025-05-26 03:38:30,249][models.s4nd][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4906221.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [512]

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.089950
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 128, 128, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 128, 128, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> -0.007878498174250126 -0.0016572276363149285 0.8206488490104675 0.836057186126709
Sample Input shape: torch.Size([4, 45, 128, 128])
Sample Output shape: torch.Size([4, 3, 128, 128])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4906222.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [256, 512]

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.085969

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.193666
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 64, 64, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 64, 64, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> 0.00751653965562582 0.007493160665035248 0.7822824120521545 0.8029276132583618
Sample Input shape: torch.Size([4, 45, 64, 64])
Sample Output shape: torch.Size([4, 3, 64, 64])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4906223.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [128, 256, 512]

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([4, 45, 128, 128]), y=torch.Size([4, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.094520

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.257956

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.515243
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (1, 250)
Combined data shape: (1, 250, 32, 32, 3)
--------Processing simulation 0----------
Dataset initialized with 235 samples
Raw data shape: (1, 250, 32, 32, 3)
Window size: 15, Flatten window: True
--------started data123----------
---------Using data normalizer---------------
Train dataset size: 188
Validation dataset size: 23
Test dataset size: 24
---------Loading all the data--------------------
<class 'torch.Tensor'> -0.002809588797390461 -0.012607487849891186 1.1854816675186157 1.2368923425674438
Sample Input shape: torch.Size([4, 45, 32, 32])
Sample Output shape: torch.Size([4, 3, 32, 32])
---------Loading all the model--------------------
Loaded model from path: ./checkpoints/s4ndmodel/navier_stokes_0_4920869.pt
S4NDModel(
  (encoder): Linear(in_features=47, out_features=64, bias=True)
  (s4_layers): ModuleList(
    (0-3): 4 x S4ND(
      (kernel): ModuleList(
        (0-1): 2 x SSMKernelDPLR()
      )
    )
  )
  (norms): ModuleList(
    (0-3): 4 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (dropouts): ModuleList(
    (0-3): 4 x Dropout(p=0.2, inplace=False)
  )
  (decoder): Linear(in_features=64, out_features=3, bias=True)
)
--------Evaluating Higher Resolution------------
Loading from file: /home/rvk/data/pdebench/ns_incom_inhom_2d_512-100.hdf5
Available keys: ['force', 'particles', 't', 'velocity']
Velocity data shape: (4, 1000, 512, 512, 2)
Particles data shape: (4, 1000, 512, 512, 1)
Time data shape: (4, 1000)
Combined data shape: (4, 1000, 512, 512, 3)
--------Processing simulation 0----------
--------Processing simulation 1----------
--------Processing simulation 2----------
--------Processing simulation 3----------
Dataset initialized with 3940 samples
Raw data shape: (4, 1000, 512, 512, 3)
Window size: 15, Flatten window: True
--------started data123----------
Train dataset size: 3152
Validation dataset size: 394
Test dataset size: 394
Original test data shape: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Testing resolutions: [64, 128, 256, 512]

Evaluating at resolution: 64
Downsampled shapes: x=torch.Size([4, 45, 64, 64]), y=torch.Size([4, 3, 64, 64])
Resolution 64 - Relative L2 Loss: 0.203947

Evaluating at resolution: 128
Downsampled shapes: x=torch.Size([4, 45, 128, 128]), y=torch.Size([4, 3, 128, 128])
Resolution 128 - Relative L2 Loss: 0.302606

Evaluating at resolution: 256
Downsampled shapes: x=torch.Size([4, 45, 256, 256]), y=torch.Size([4, 3, 256, 256])
Resolution 256 - Relative L2 Loss: 0.518819

Evaluating at resolution: 512
Downsampled shapes: x=torch.Size([4, 45, 512, 512]), y=torch.Size([4, 3, 512, 512])
Resolution 512 - Relative L2 Loss: 0.654276
Job completed at Mon May 26 03:41:35 EDT 2025
